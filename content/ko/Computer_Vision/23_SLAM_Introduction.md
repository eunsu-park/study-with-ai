# SLAM ì…ë¬¸ (Visual SLAM Introduction)

## ê°œìš”

SLAM (Simultaneous Localization and Mapping)ì€ ë¡œë´‡ì´ë‚˜ ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œì´ ë¯¸ì§€ì˜ í™˜ê²½ì—ì„œ ì§€ë„ë¥¼ ì‘ì„±í•˜ë©´ì„œ ë™ì‹œì— ìì‹ ì˜ ìœ„ì¹˜ë¥¼ ì¶”ì •í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. Visual SLAM, LiDAR SLAM, Loop Closureì˜ ê¸°ì´ˆë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.

**ë‚œì´ë„**: â­â­â­â­

**ì„ ìˆ˜ ì§€ì‹**: 3D ë¹„ì „, íŠ¹ì§•ì  ê²€ì¶œ/ë§¤ì¹­, ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜, ê¸°ë³¸ í™•ë¥ ë¡ 

---

## ëª©ì°¨

1. [SLAM ê°œìš”](#1-slam-ê°œìš”)
2. [Visual Odometry](#2-visual-odometry)
3. [ORB-SLAM](#3-orb-slam)
4. [LiDAR SLAM](#4-lidar-slam)
5. [Loop Closure](#5-loop-closure)
6. [SLAM êµ¬í˜„ ì‹¤ìŠµ](#6-slam-êµ¬í˜„-ì‹¤ìŠµ)
7. [ì—°ìŠµ ë¬¸ì œ](#7-ì—°ìŠµ-ë¬¸ì œ)

---

## 1. SLAM ê°œìš”

### SLAMì´ë€?

```
SLAM (Simultaneous Localization and Mapping):
ë™ì‹œì  ìœ„ì¹˜ì¶”ì • ë° ì§€ë„ì‘ì„±

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  í•µì‹¬ ì§ˆë¬¸:                                                     â”‚
â”‚  "ì§€ë„ ì—†ì´ ì–´ë–»ê²Œ ìœ„ì¹˜ë¥¼ ì•Œ ìˆ˜ ìˆëŠ”ê°€?"                        â”‚
â”‚  "ìœ„ì¹˜ë¥¼ ëª¨ë¥´ë©´ì„œ ì–´ë–»ê²Œ ì§€ë„ë¥¼ ë§Œë“¤ ìˆ˜ ìˆëŠ”ê°€?"                â”‚
â”‚                                                                 â”‚
â”‚  â†’ ë‘˜ì„ ë™ì‹œì— í•´ê²°! (ë‹­ê³¼ ë‹¬ê±€ ë¬¸ì œ)                           â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                                                        â”‚     â”‚
â”‚  â”‚     ì„¼ì„œ ë°ì´í„°                                        â”‚     â”‚
â”‚  â”‚     (ì¹´ë©”ë¼, LiDAR, IMU)                               â”‚     â”‚
â”‚  â”‚            â”‚                                           â”‚     â”‚
â”‚  â”‚            â–¼                                           â”‚     â”‚
â”‚  â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚     â”‚
â”‚  â”‚     â”‚    SLAM      â”‚                                   â”‚     â”‚
â”‚  â”‚     â”‚   ì•Œê³ ë¦¬ì¦˜   â”‚                                   â”‚     â”‚
â”‚  â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚     â”‚
â”‚  â”‚            â”‚                                           â”‚     â”‚
â”‚  â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚     â”‚
â”‚  â”‚     â”‚              â”‚                                   â”‚     â”‚
â”‚  â”‚     â–¼              â–¼                                   â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚     â”‚
â”‚  â”‚  â”‚  ì§€ë„   â”‚  â”‚  ìœ„ì¹˜   â”‚                             â”‚     â”‚
â”‚  â”‚  â”‚  (Map)  â”‚  â”‚ (Pose)  â”‚                             â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚     â”‚
â”‚  â”‚                                                        â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ì‘ìš© ë¶„ì•¼:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ë¶„ì•¼            â”‚ ì˜ˆì‹œ                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ììœ¨ì£¼í–‰        â”‚ ìë™ì°¨, ë“œë¡ , ë°°ë‹¬ ë¡œë´‡                 â”‚
â”‚ ì¦ê°•í˜„ì‹¤        â”‚ ARKit, ARCore, HoloLens                 â”‚
â”‚ ë¡œë´‡ ì²­ì†Œê¸°     â”‚ Roomba, Roborock                        â”‚
â”‚ 3D ìŠ¤ìºë‹       â”‚ ê±´ì¶•, ë¬¸í™”ì¬ ë³µì›                       â”‚
â”‚ ë‚´ë¹„ê²Œì´ì…˜      â”‚ ì‹¤ë‚´ ìœ„ì¹˜ ì¸ì‹                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### SLAM ë¶„ë¥˜

```
SLAM ë°©ì‹ ë¶„ë¥˜:

1. ì„¼ì„œ ê¸°ë°˜ ë¶„ë¥˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  Visual SLAM (V-SLAM)                                           â”‚
â”‚  - ì¹´ë©”ë¼ (ë‹¨ì•ˆ, ìŠ¤í…Œë ˆì˜¤, RGB-D)                               â”‚
â”‚  - íŠ¹ì§•ì  ê¸°ë°˜ ë˜ëŠ” ì§ì ‘ ë°©ì‹                                   â”‚
â”‚  - ì˜ˆ: ORB-SLAM, LSD-SLAM, DSO                                 â”‚
â”‚                                                                 â”‚
â”‚  LiDAR SLAM                                                     â”‚
â”‚  - ë ˆì´ì € ìŠ¤ìºë„ˆ                                                â”‚
â”‚  - í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë§¤ì¹­                                         â”‚
â”‚  - ì˜ˆ: Cartographer, LOAM, LeGO-LOAM                           â”‚
â”‚                                                                 â”‚
â”‚  Visual-Inertial SLAM                                           â”‚
â”‚  - ì¹´ë©”ë¼ + IMU ìœµí•©                                            â”‚
â”‚  - ì˜ˆ: VINS-Mono, OKVIS, MSCKF                                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2. ë°©ë²•ë¡  ê¸°ë°˜ ë¶„ë¥˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  í•„í„° ê¸°ë°˜ (Filter-based)                                       â”‚
â”‚  - EKF-SLAM, UKF-SLAM                                          â”‚
â”‚  - ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸                                              â”‚
â”‚  - ì„ í˜•í™” ì˜¤ë¥˜ ëˆ„ì  ë¬¸ì œ                                        â”‚
â”‚                                                                 â”‚
â”‚  ê·¸ë˜í”„ ê¸°ë°˜ (Graph-based)                                      â”‚
â”‚  - í¬ì¦ˆ ê·¸ë˜í”„ ìµœì í™”                                           â”‚
â”‚  - ë²ˆë“¤ ì¡°ì •                                                    â”‚
â”‚  - ë” ì •í™•í•˜ì§€ë§Œ ê³„ì‚° ë¹„ìš© ë†’ìŒ                                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3. í”„ë¡ íŠ¸ì—”ë“œ/ë°±ì—”ë“œ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  í”„ë¡ íŠ¸ì—”ë“œ (Front-end)                                         â”‚
â”‚  - ì„¼ì„œ ë°ì´í„° ì²˜ë¦¬                                             â”‚
â”‚  - íŠ¹ì§• ì¶”ì¶œ ë° ë§¤ì¹­                                            â”‚
â”‚  - ì´ˆê¸° í¬ì¦ˆ ì¶”ì •                                               â”‚
â”‚  - ë£¨í”„ í´ë¡œì € íƒì§€                                             â”‚
â”‚                                                                 â”‚
â”‚  ë°±ì—”ë“œ (Back-end)                                              â”‚
â”‚  - ì „ì—­ ìµœì í™”                                                  â”‚
â”‚  - ê·¸ë˜í”„ ìµœì í™”                                                â”‚
â”‚  - ë¶ˆí™•ì‹¤ì„± ì¶”ì •                                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Visual Odometry

### Visual Odometry ê°œë…

```
Visual Odometry (VO):
ì—°ì†ëœ ì´ë¯¸ì§€ë¡œë¶€í„° ì¹´ë©”ë¼ ì›€ì§ì„ ì¶”ì •

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  í”„ë ˆì„ t-1        í”„ë ˆì„ t          í”„ë ˆì„ t+1                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚   ğŸ“·  â”‚â”€â”€Tâ‚â”€â”€â”€â–¶â”‚   ğŸ“·  â”‚â”€â”€Tâ‚‚â”€â”€â”€â–¶â”‚   ğŸ“·  â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                 â”‚
â”‚  ëˆ„ì  í¬ì¦ˆ: P_t = Tâ‚ * Tâ‚‚ * ... * T_t                           â”‚
â”‚                                                                 â”‚
â”‚  ë¬¸ì œì :                                                        â”‚
â”‚  - ëˆ„ì  ì˜¤ì°¨ (drift)                                            â”‚
â”‚  - ìŠ¤ì¼€ì¼ ëª¨í˜¸ì„± (ë‹¨ì•ˆ ì¹´ë©”ë¼)                                  â”‚
â”‚  - ë¹ ë¥¸ ì›€ì§ì„ì— ì·¨ì•½                                           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

VO íŒŒì´í”„ë¼ì¸:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  1. ì´ë¯¸ì§€ íšë“                                                 â”‚
â”‚       â–¼                                                         â”‚
â”‚  2. íŠ¹ì§• ì¶”ì¶œ (ORB, SIFT, Harris corners)                       â”‚
â”‚       â–¼                                                         â”‚
â”‚  3. íŠ¹ì§• ë§¤ì¹­/ì¶”ì  (BF Matcher, Optical Flow)                   â”‚
â”‚       â–¼                                                         â”‚
â”‚  4. ëª¨ì…˜ ì¶”ì • (Essential Matrix, PnP)                           â”‚
â”‚       â–¼                                                         â”‚
â”‚  5. ì§€ì—­ ìµœì í™” (Local BA)                                      â”‚
â”‚       â–¼                                                         â”‚
â”‚  6. í¬ì¦ˆ ì—…ë°ì´íŠ¸                                               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ë‹¨ì•ˆ Visual Odometry êµ¬í˜„

```python
import cv2
import numpy as np

class MonocularVO:
    """ë‹¨ì•ˆ Visual Odometry"""

    def __init__(self, K, detector='ORB'):
        """
        K: ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° í–‰ë ¬
        detector: íŠ¹ì§•ì  ê²€ì¶œê¸° ('ORB', 'SIFT', 'FAST')
        """
        self.K = K
        self.focal = K[0, 0]
        self.pp = (K[0, 2], K[1, 2])  # principal point

        # íŠ¹ì§•ì  ê²€ì¶œê¸°
        if detector == 'ORB':
            self.detector = cv2.ORB_create(3000)
        elif detector == 'SIFT':
            self.detector = cv2.SIFT_create(3000)
        else:
            self.detector = cv2.FastFeatureDetector_create(threshold=25)

        # ê´‘í•™ íë¦„ íŒŒë¼ë¯¸í„°
        self.lk_params = dict(
            winSize=(21, 21),
            maxLevel=3,
            criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01)
        )

        # ìƒíƒœ
        self.prev_frame = None
        self.prev_pts = None
        self.cur_R = np.eye(3)
        self.cur_t = np.zeros((3, 1))
        self.trajectory = []

    def detect_features(self, img):
        """íŠ¹ì§•ì  ê²€ì¶œ"""
        if hasattr(self.detector, 'detectAndCompute'):
            kp, _ = self.detector.detectAndCompute(img, None)
        else:
            kp = self.detector.detect(img, None)

        pts = np.array([p.pt for p in kp], dtype=np.float32)
        return pts.reshape(-1, 1, 2)

    def track_features(self, prev_img, cur_img, prev_pts):
        """ê´‘í•™ íë¦„ìœ¼ë¡œ íŠ¹ì§•ì  ì¶”ì """

        cur_pts, status, err = cv2.calcOpticalFlowPyrLK(
            prev_img, cur_img, prev_pts, None, **self.lk_params
        )

        status = status.reshape(-1)
        prev_pts = prev_pts[status == 1]
        cur_pts = cur_pts[status == 1]

        return prev_pts, cur_pts

    def estimate_pose(self, pts1, pts2):
        """Essential Matrixë¡œ í¬ì¦ˆ ì¶”ì •"""

        E, mask = cv2.findEssentialMat(
            pts1, pts2, self.K,
            method=cv2.RANSAC,
            prob=0.999,
            threshold=1.0
        )

        _, R, t, mask = cv2.recoverPose(E, pts1, pts2, self.K)

        return R, t

    def process_frame(self, frame):
        """í”„ë ˆì„ ì²˜ë¦¬"""

        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(frame.shape) == 3:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        else:
            gray = frame

        if self.prev_frame is None:
            # ì²« í”„ë ˆì„
            self.prev_frame = gray
            self.prev_pts = self.detect_features(gray)
            return self.cur_R, self.cur_t

        # íŠ¹ì§•ì  ì¶”ì 
        if self.prev_pts is not None and len(self.prev_pts) > 0:
            prev_pts, cur_pts = self.track_features(
                self.prev_frame, gray, self.prev_pts
            )

            if len(prev_pts) >= 8:
                # í¬ì¦ˆ ì¶”ì •
                R, t = self.estimate_pose(
                    prev_pts.reshape(-1, 2),
                    cur_pts.reshape(-1, 2)
                )

                # í¬ì¦ˆ ëˆ„ì 
                self.cur_t = self.cur_t + self.cur_R @ t
                self.cur_R = R @ self.cur_R

                # ìƒˆ íŠ¹ì§•ì ì´ í•„ìš”í•˜ë©´ ê²€ì¶œ
                if len(cur_pts) < 1000:
                    new_pts = self.detect_features(gray)
                    if len(cur_pts) > 0:
                        self.prev_pts = np.vstack([
                            cur_pts.reshape(-1, 1, 2),
                            new_pts
                        ])
                    else:
                        self.prev_pts = new_pts
                else:
                    self.prev_pts = cur_pts.reshape(-1, 1, 2)
            else:
                self.prev_pts = self.detect_features(gray)
        else:
            self.prev_pts = self.detect_features(gray)

        self.prev_frame = gray

        # ê¶¤ì  ì €ì¥
        self.trajectory.append(self.cur_t.copy())

        return self.cur_R, self.cur_t

    def get_trajectory(self):
        """ê¶¤ì  ë°˜í™˜"""
        return np.array([t.ravel() for t in self.trajectory])

# ì‚¬ìš© ì˜ˆ
K = np.array([
    [718.856, 0, 607.1928],
    [0, 718.856, 185.2157],
    [0, 0, 1]
], dtype=np.float32)

vo = MonocularVO(K)

cap = cv2.VideoCapture('driving.mp4')

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    R, t = vo.process_frame(frame)

    # í˜„ì¬ ìœ„ì¹˜ ì¶œë ¥
    x, y, z = t.ravel()
    print(f"Position: x={x:.2f}, y={y:.2f}, z={z:.2f}")

cap.release()

# ê¶¤ì  ì‹œê°í™”
trajectory = vo.get_trajectory()
```

### ìŠ¤í…Œë ˆì˜¤ Visual Odometry

```python
class StereoVO:
    """ìŠ¤í…Œë ˆì˜¤ Visual Odometry"""

    def __init__(self, K, baseline, detector='ORB'):
        self.K = K
        self.baseline = baseline
        self.focal = K[0, 0]

        self.detector = cv2.ORB_create(3000)
        self.bf = cv2.BFMatcher(cv2.NORM_HAMMING)

        # ìŠ¤í…Œë ˆì˜¤ ë§¤ì²˜
        self.stereo = cv2.StereoSGBM_create(
            minDisparity=0,
            numDisparities=128,
            blockSize=5,
            P1=8 * 3 * 5 ** 2,
            P2=32 * 3 * 5 ** 2
        )

        self.prev_pts_3d = None
        self.prev_kp = None
        self.prev_desc = None
        self.cur_R = np.eye(3)
        self.cur_t = np.zeros((3, 1))

    def compute_depth(self, left, right):
        """ìŠ¤í…Œë ˆì˜¤ ë§¤ì¹­ìœ¼ë¡œ ê¹Šì´ ê³„ì‚°"""

        disparity = self.stereo.compute(left, right).astype(np.float32) / 16.0

        # ì‹œì°¨ â†’ ê¹Šì´
        depth = np.zeros_like(disparity)
        valid = disparity > 0
        depth[valid] = self.focal * self.baseline / disparity[valid]

        return depth

    def get_3d_points(self, kp, depth):
        """2D í‚¤í¬ì¸íŠ¸ë¥¼ 3Dë¡œ ë³€í™˜"""

        fx = self.K[0, 0]
        fy = self.K[1, 1]
        cx = self.K[0, 2]
        cy = self.K[1, 2]

        pts_3d = []
        valid_indices = []

        for i, pt in enumerate(kp):
            x, y = int(pt.pt[0]), int(pt.pt[1])

            if 0 <= x < depth.shape[1] and 0 <= y < depth.shape[0]:
                z = depth[y, x]

                if z > 0 and z < 100:  # ìœ íš¨í•œ ê¹Šì´
                    X = (pt.pt[0] - cx) * z / fx
                    Y = (pt.pt[1] - cy) * z / fy
                    pts_3d.append([X, Y, z])
                    valid_indices.append(i)

        return np.array(pts_3d), valid_indices

    def process_frame(self, left, right):
        """ìŠ¤í…Œë ˆì˜¤ í”„ë ˆì„ ì²˜ë¦¬"""

        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
        gray_left = cv2.cvtColor(left, cv2.COLOR_BGR2GRAY)
        gray_right = cv2.cvtColor(right, cv2.COLOR_BGR2GRAY)

        # ê¹Šì´ ê³„ì‚°
        depth = self.compute_depth(gray_left, gray_right)

        # íŠ¹ì§• ê²€ì¶œ
        kp, desc = self.detector.detectAndCompute(gray_left, None)

        # 3D ì  ê³„ì‚°
        pts_3d, valid_idx = self.get_3d_points(kp, depth)

        if self.prev_pts_3d is None:
            self.prev_pts_3d = pts_3d
            self.prev_kp = [kp[i] for i in valid_idx]
            self.prev_desc = desc[valid_idx]
            return self.cur_R, self.cur_t

        # ì´ì „ í”„ë ˆì„ê³¼ ë§¤ì¹­
        matches = self.bf.knnMatch(self.prev_desc, desc[valid_idx], k=2)

        good_matches = []
        for m, n in matches:
            if m.distance < 0.7 * n.distance:
                good_matches.append(m)

        if len(good_matches) >= 6:
            # 3D-2D ëŒ€ì‘ì 
            obj_points = np.array([
                self.prev_pts_3d[m.queryIdx] for m in good_matches
            ])
            img_points = np.array([
                kp[valid_idx[m.trainIdx]].pt for m in good_matches
            ])

            # PnPë¡œ í¬ì¦ˆ ì¶”ì •
            success, rvec, tvec, inliers = cv2.solvePnPRansac(
                obj_points, img_points, self.K, None
            )

            if success and inliers is not None and len(inliers) > 10:
                R, _ = cv2.Rodrigues(rvec)

                # í¬ì¦ˆ ëˆ„ì 
                self.cur_t = self.cur_t + self.cur_R @ tvec
                self.cur_R = R @ self.cur_R

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        self.prev_pts_3d = pts_3d
        self.prev_kp = [kp[i] for i in valid_idx]
        self.prev_desc = desc[valid_idx]

        return self.cur_R, self.cur_t
```

---

## 3. ORB-SLAM

### ORB-SLAM ê°œìš”

```
ORB-SLAM ì•„í‚¤í…ì²˜:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  ORB-SLAM: ê°€ì¥ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” Visual SLAM ì‹œìŠ¤í…œ                â”‚
â”‚                                                                 â”‚
â”‚  ë²„ì „:                                                          â”‚
â”‚  - ORB-SLAM (2015): ë‹¨ì•ˆ                                        â”‚
â”‚  - ORB-SLAM2 (2017): ë‹¨ì•ˆ/ìŠ¤í…Œë ˆì˜¤/RGB-D                        â”‚
â”‚  - ORB-SLAM3 (2021): Visual-Inertial, ë‹¤ì¤‘ ë§µ                   â”‚
â”‚                                                                 â”‚
â”‚  3ê°œì˜ ë³‘ë ¬ ìŠ¤ë ˆë“œ:                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚  â”‚  Tracking   â”‚  â”‚Local Mappingâ”‚  â”‚Loop Closing â”‚     â”‚    â”‚
â”‚  â”‚  â”‚   Thread    â”‚  â”‚   Thread    â”‚  â”‚   Thread    â”‚     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â”‚         â”‚                â”‚                â”‚            â”‚    â”‚
â”‚  â”‚         â”‚    Keyframes   â”‚                â”‚            â”‚    â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                â”‚            â”‚    â”‚
â”‚  â”‚                          â”‚    Keyframes   â”‚            â”‚    â”‚
â”‚  â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚            â”‚    â”‚
â”‚  â”‚                                           â”‚            â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚            â”‚    â”‚
â”‚  â”‚  â”‚           Map (MapPoints)             â”‚â”‚            â”‚    â”‚
â”‚  â”‚  â”‚         & Covisibility Graph          â”‚â”‚            â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚            â”‚    â”‚
â”‚  â”‚                                           â”‚            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Tracking ìŠ¤ë ˆë“œ:
- ë§¤ í”„ë ˆì„ ì²˜ë¦¬
- ORB íŠ¹ì§• ì¶”ì¶œ
- ì´ì „ í”„ë ˆì„ ë˜ëŠ” ë§µê³¼ ë§¤ì¹­
- ì´ˆê¸° í¬ì¦ˆ ì¶”ì •
- í‚¤í”„ë ˆì„ ê²°ì •

Local Mapping ìŠ¤ë ˆë“œ:
- ìƒˆ í‚¤í”„ë ˆì„ ì‚½ì…
- ìµœê·¼ MapPoint ì»¬ë§
- ìƒˆ MapPoint ìƒì„±
- Local Bundle Adjustment
- ì¤‘ë³µ í‚¤í”„ë ˆì„ ì œê±°

Loop Closing ìŠ¤ë ˆë“œ:
- ë£¨í”„ í›„ë³´ ê²€ì¶œ (DBoW2)
- ë£¨í”„ ê²€ì¦ ë° ë³´ì •
- Essential Graph ìµœì í™”
- ì „ì—­ Bundle Adjustment
```

### ORB íŠ¹ì§•ê³¼ Bag of Words

```python
import cv2
import numpy as np

class ORBVocabulary:
    """ORB ê¸°ë°˜ Bag of Words"""

    def __init__(self, num_words=1000):
        self.orb = cv2.ORB_create(1000)
        self.num_words = num_words
        self.vocabulary = None
        self.bf = cv2.BFMatcher(cv2.NORM_HAMMING)

    def train(self, images):
        """ì´ë¯¸ì§€ë¡œë¶€í„° vocabulary í•™ìŠµ"""

        all_descriptors = []

        for img in images:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            _, desc = self.orb.detectAndCompute(gray, None)
            if desc is not None:
                all_descriptors.append(desc)

        all_desc = np.vstack(all_descriptors)

        # K-means í´ëŸ¬ìŠ¤í„°ë§
        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,
                   100, 0.2)
        _, labels, centers = cv2.kmeans(
            all_desc.astype(np.float32),
            self.num_words,
            None,
            criteria,
            10,
            cv2.KMEANS_RANDOM_CENTERS
        )

        self.vocabulary = centers.astype(np.uint8)
        print(f"Vocabulary ìƒì„± ì™„ë£Œ: {self.num_words} words")

    def compute_bow(self, img):
        """ì´ë¯¸ì§€ì˜ BoW ë²¡í„° ê³„ì‚°"""

        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        _, desc = self.orb.detectAndCompute(gray, None)

        if desc is None:
            return np.zeros(self.num_words)

        # ê° ë””ìŠ¤í¬ë¦½í„°ë¥¼ ê°€ì¥ ê°€ê¹Œìš´ vocabulary wordì— í• ë‹¹
        matches = self.bf.match(desc, self.vocabulary)

        bow = np.zeros(self.num_words)
        for m in matches:
            bow[m.trainIdx] += 1

        # ì •ê·œí™”
        bow = bow / (np.linalg.norm(bow) + 1e-6)

        return bow

    def compute_similarity(self, bow1, bow2):
        """ë‘ BoW ë²¡í„°ì˜ ìœ ì‚¬ë„"""
        return np.dot(bow1, bow2)


class SimpleSLAM:
    """ê°„ë‹¨í•œ SLAM ì‹œìŠ¤í…œ (ORB-SLAM ì»¨ì…‰)"""

    def __init__(self, K):
        self.K = K
        self.orb = cv2.ORB_create(2000)
        self.bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

        # ë§µ
        self.keyframes = []      # í‚¤í”„ë ˆì„ ëª©ë¡
        self.map_points = []     # 3D í¬ì¸íŠ¸
        self.poses = []          # í‚¤í”„ë ˆì„ í¬ì¦ˆ

        # í˜„ì¬ ìƒíƒœ
        self.cur_R = np.eye(3)
        self.cur_t = np.zeros((3, 1))
        self.prev_frame = None
        self.prev_kp = None
        self.prev_desc = None

        # í‚¤í”„ë ˆì„ ê¸°ì¤€
        self.kf_threshold = 30   # ìµœì†Œ ë§¤ì¹­ ìˆ˜

    def is_keyframe(self, num_matches, motion):
        """í‚¤í”„ë ˆì„ ì—¬ë¶€ ê²°ì •"""

        # ê°„ë‹¨í•œ ê¸°ì¤€: ë§¤ì¹­ ìˆ˜ê°€ ì ê±°ë‚˜ ì›€ì§ì„ì´ í¬ë©´ í‚¤í”„ë ˆì„
        translation = np.linalg.norm(motion)

        if num_matches < self.kf_threshold or translation > 0.5:
            return True
        return False

    def add_keyframe(self, frame, kp, desc, pose):
        """í‚¤í”„ë ˆì„ ì¶”ê°€"""

        keyframe = {
            'frame': frame.copy(),
            'keypoints': kp,
            'descriptors': desc,
            'pose': pose.copy()
        }

        self.keyframes.append(keyframe)
        self.poses.append(pose)

        print(f"Keyframe ì¶”ê°€: ì´ {len(self.keyframes)}ê°œ")

    def process_frame(self, frame):
        """í”„ë ˆì„ ì²˜ë¦¬ (Tracking)"""

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        kp, desc = self.orb.detectAndCompute(gray, None)

        if self.prev_frame is None:
            # ì²« í”„ë ˆì„ â†’ í‚¤í”„ë ˆì„
            pose = {'R': np.eye(3), 't': np.zeros((3, 1))}
            self.add_keyframe(gray, kp, desc, pose)
            self.prev_frame = gray
            self.prev_kp = kp
            self.prev_desc = desc
            return self.cur_R, self.cur_t

        # ì´ì „ í”„ë ˆì„ê³¼ ë§¤ì¹­
        matches = self.bf.match(self.prev_desc, desc)
        matches = sorted(matches, key=lambda x: x.distance)[:500]

        if len(matches) >= 8:
            # ë§¤ì¹­ì  ì¶”ì¶œ
            pts1 = np.float32([self.prev_kp[m.queryIdx].pt for m in matches])
            pts2 = np.float32([kp[m.trainIdx].pt for m in matches])

            # Essential Matrixë¡œ í¬ì¦ˆ ì¶”ì •
            E, mask = cv2.findEssentialMat(pts1, pts2, self.K)
            _, R, t, mask = cv2.recoverPose(E, pts1, pts2, self.K)

            # í¬ì¦ˆ ëˆ„ì 
            self.cur_t = self.cur_t + self.cur_R @ t
            self.cur_R = R @ self.cur_R

            # í‚¤í”„ë ˆì„ ì²´í¬
            if self.is_keyframe(len(matches), t):
                pose = {'R': self.cur_R.copy(), 't': self.cur_t.copy()}
                self.add_keyframe(gray, kp, desc, pose)

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        self.prev_frame = gray
        self.prev_kp = kp
        self.prev_desc = desc

        return self.cur_R, self.cur_t

    def get_camera_trajectory(self):
        """ì¹´ë©”ë¼ ê¶¤ì  ë°˜í™˜"""
        trajectory = []
        for pose in self.poses:
            R = pose['R']
            t = pose['t']
            # ì¹´ë©”ë¼ ìœ„ì¹˜ = -R^T * t
            pos = -R.T @ t
            trajectory.append(pos.ravel())
        return np.array(trajectory)
```

---

## 4. LiDAR SLAM

### LiDAR SLAM ê°œìš”

```
LiDAR SLAM:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  LiDAR ì„¼ì„œ íŠ¹ì§•:                                               â”‚
â”‚  - 360ë„ ìŠ¤ìº”                                                   â”‚
â”‚  - ì •í™•í•œ ê±°ë¦¬ ì¸¡ì •                                             â”‚
â”‚  - ì¡°ëª… ì¡°ê±´ì— ê°•ê±´                                             â”‚
â”‚  - í’ë¶€í•œ 3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œ                                    â”‚
â”‚                                                                 â”‚
â”‚  LiDAR ì¢…ë¥˜:                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ 2D LiDAR         â”‚ í‰ë©´ ìŠ¤ìº”, ì €ë ´, ë¡œë´‡ ì²­ì†Œê¸°        â”‚     â”‚
â”‚  â”‚ (ì˜ˆ: RPLiDAR)    â”‚                                     â”‚     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚ 3D LiDAR         â”‚ 3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œ, ììœ¨ì£¼í–‰       â”‚     â”‚
â”‚  â”‚ (ì˜ˆ: Velodyne)   â”‚                                     â”‚     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚ Solid-State      â”‚ ë¬´íšŒì „, ì†Œí˜•, ìµœì‹  íŠ¸ë Œë“œ          â”‚     â”‚
â”‚  â”‚ (ì˜ˆ: Livox)      â”‚                                     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                 â”‚
â”‚  ì£¼ìš” ì•Œê³ ë¦¬ì¦˜:                                                 â”‚
â”‚  - ICP (Iterative Closest Point)                               â”‚
â”‚  - NDT (Normal Distributions Transform)                        â”‚
â”‚  - LOAM (LiDAR Odometry and Mapping)                           â”‚
â”‚  - LeGO-LOAM (Lightweight Ground-Optimized)                    â”‚
â”‚  - Cartographer (Google)                                        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ICP (Iterative Closest Point)

```python
import numpy as np
from scipy.spatial import KDTree

def icp(source, target, max_iterations=50, tolerance=1e-6):
    """
    ICP ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë‘ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì •í•©

    Parameters:
        source: ì†ŒìŠ¤ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ (N x 3)
        target: íƒ€ê²Ÿ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ (M x 3)

    Returns:
        R: íšŒì „ í–‰ë ¬ (3 x 3)
        t: í‰í–‰ ì´ë™ ë²¡í„° (3,)
        transformed: ë³€í™˜ëœ ì†ŒìŠ¤ í¬ì¸íŠ¸
    """

    src = source.copy()
    prev_error = float('inf')

    R_total = np.eye(3)
    t_total = np.zeros(3)

    # KD-Treeë¡œ íš¨ìœ¨ì ì¸ ìµœê·¼ì ‘ íƒìƒ‰
    tree = KDTree(target)

    for i in range(max_iterations):
        # 1. ìµœê·¼ì ‘ ëŒ€ì‘ì  ì°¾ê¸°
        distances, indices = tree.query(src)
        correspondences = target[indices]

        # 2. ë³€í™˜ ì¶”ì • (SVD)
        src_centroid = np.mean(src, axis=0)
        tgt_centroid = np.mean(correspondences, axis=0)

        src_centered = src - src_centroid
        tgt_centered = correspondences - tgt_centroid

        H = src_centered.T @ tgt_centered
        U, _, Vt = np.linalg.svd(H)
        R = Vt.T @ U.T

        # ë°˜ì‚¬ ë³´ì •
        if np.linalg.det(R) < 0:
            Vt[-1, :] *= -1
            R = Vt.T @ U.T

        t = tgt_centroid - R @ src_centroid

        # 3. ë³€í™˜ ì ìš©
        src = (R @ src.T).T + t

        # ëˆ„ì  ë³€í™˜
        R_total = R @ R_total
        t_total = R @ t_total + t

        # 4. ìˆ˜ë ´ í™•ì¸
        mean_error = np.mean(distances)
        if abs(prev_error - mean_error) < tolerance:
            print(f"ICP ìˆ˜ë ´: {i+1} ë°˜ë³µ, ì˜¤ì°¨: {mean_error:.6f}")
            break
        prev_error = mean_error

    return R_total, t_total, src

class LiDARSLAM:
    """ê°„ë‹¨í•œ 2D LiDAR SLAM"""

    def __init__(self, map_resolution=0.05):
        self.resolution = map_resolution
        self.pose = np.array([0.0, 0.0, 0.0])  # x, y, theta
        self.trajectory = [self.pose.copy()]

        # ì ìœ  ê²©ì ë§µ
        self.map_size = 1000
        self.occupancy_map = np.ones((self.map_size, self.map_size)) * 0.5
        self.map_origin = np.array([self.map_size // 2, self.map_size // 2])

    def scan_to_points(self, scan_ranges, scan_angles):
        """ìŠ¤ìº” ë°ì´í„°ë¥¼ 2D í¬ì¸íŠ¸ë¡œ ë³€í™˜"""

        valid = (scan_ranges > 0.1) & (scan_ranges < 30.0)
        ranges = scan_ranges[valid]
        angles = scan_angles[valid]

        x = ranges * np.cos(angles)
        y = ranges * np.sin(angles)

        return np.column_stack([x, y])

    def transform_points(self, points, pose):
        """í¬ì¸íŠ¸ë¥¼ ì›”ë“œ ì¢Œí‘œë¡œ ë³€í™˜"""

        x, y, theta = pose
        R = np.array([
            [np.cos(theta), -np.sin(theta)],
            [np.sin(theta), np.cos(theta)]
        ])

        transformed = (R @ points.T).T + np.array([x, y])
        return transformed

    def point_to_grid(self, points):
        """í¬ì¸íŠ¸ë¥¼ ê·¸ë¦¬ë“œ ì¢Œí‘œë¡œ ë³€í™˜"""

        grid_x = (points[:, 0] / self.resolution + self.map_origin[0]).astype(int)
        grid_y = (points[:, 1] / self.resolution + self.map_origin[1]).astype(int)

        # ë§µ ë²”ìœ„ ë‚´ë¡œ ì œí•œ
        valid = (grid_x >= 0) & (grid_x < self.map_size) & \
                (grid_y >= 0) & (grid_y < self.map_size)

        return grid_x[valid], grid_y[valid], valid

    def update_map(self, scan_points, pose):
        """ì ìœ  ê²©ì ë§µ ì—…ë°ì´íŠ¸"""

        world_points = self.transform_points(scan_points, pose)
        gx, gy, valid = self.point_to_grid(world_points)

        # ì ìœ  í™•ë¥  ì—…ë°ì´íŠ¸ (ë¡œê·¸ ì˜¤ì¦ˆ)
        self.occupancy_map[gy, gx] = np.clip(
            self.occupancy_map[gy, gx] + 0.1, 0, 1
        )

    def match_scan(self, current_points, previous_points):
        """ìŠ¤ìº” ë§¤ì¹­ìœ¼ë¡œ ìƒëŒ€ ì´ë™ ì¶”ì •"""

        if len(previous_points) < 10 or len(current_points) < 10:
            return np.array([0, 0, 0])

        # ICP ì ìš©
        R, t, _ = icp(current_points, previous_points)

        # 2Dì—ì„œ theta ì¶”ì¶œ
        theta = np.arctan2(R[1, 0], R[0, 0])

        return np.array([t[0], t[1], theta])

    def process_scan(self, scan_ranges, scan_angles, prev_scan=None):
        """ìŠ¤ìº” ì²˜ë¦¬"""

        current_points = self.scan_to_points(scan_ranges, scan_angles)

        if prev_scan is not None:
            prev_points = self.scan_to_points(prev_scan[0], prev_scan[1])

            # ìŠ¤ìº” ë§¤ì¹­
            delta_pose = self.match_scan(current_points, prev_points)

            # í¬ì¦ˆ ì—…ë°ì´íŠ¸
            self.pose[2] += delta_pose[2]
            R = np.array([
                [np.cos(self.pose[2]), -np.sin(self.pose[2])],
                [np.sin(self.pose[2]), np.cos(self.pose[2])]
            ])
            self.pose[:2] += R @ delta_pose[:2]

        # ë§µ ì—…ë°ì´íŠ¸
        self.update_map(current_points, self.pose)

        # ê¶¤ì  ì €ì¥
        self.trajectory.append(self.pose.copy())

        return self.pose

    def get_occupancy_map(self):
        """ì ìœ  ë§µ ë°˜í™˜"""
        return self.occupancy_map

    def get_trajectory(self):
        """ê¶¤ì  ë°˜í™˜"""
        return np.array(self.trajectory)
```

---

## 5. Loop Closure

### Loop Closure ê°œë…

```
Loop Closure (ë£¨í”„ íí•©):
ì´ì „ì— ë°©ë¬¸í•œ ì¥ì†Œë¥¼ ì¬ì¸ì‹í•˜ì—¬ ëˆ„ì  ì˜¤ì°¨ ë³´ì •

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  ë¬¸ì œ: Drift (ëˆ„ì  ì˜¤ì°¨)                                        â”‚
â”‚                                                                 â”‚
â”‚       ì‹¤ì œ ê²½ë¡œ        ì¶”ì • ê²½ë¡œ (drift ìˆìŒ)                   â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚       â”‚         â”‚      â”‚         â•²                              â”‚
â”‚       â”‚         â”‚      â”‚          â•²                             â”‚
â”‚       â”‚         â”‚      â”‚           â•²                            â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²                           â”‚
â”‚       (íê³¡ì„ )          (ì—´ë¦° ê³¡ì„ )                             â”‚
â”‚                                                                 â”‚
â”‚  í•´ê²°: Loop Closure                                             â”‚
â”‚       1. í˜„ì¬ ìœ„ì¹˜ê°€ ì´ì „ì— ë°©ë¬¸í•œ ê³³ì¸ì§€ íƒì§€                  â”‚
â”‚       2. ë£¨í”„ ì œì•½ ì¡°ê±´ ì¶”ê°€                                    â”‚
â”‚       3. í¬ì¦ˆ ê·¸ë˜í”„ ìµœì í™”                                     â”‚
â”‚                                                                 â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚       â”‚    â—â”€â”€â”€â”€â—  â† ë£¨í”„ íƒì§€                                  â”‚
â”‚       â”‚    â”‚    â”‚                                               â”‚
â”‚       â”‚    â”‚    â”‚  â† ê·¸ë˜í”„ ìµœì í™”                              â”‚
â”‚       â”‚    â—â”€â”€â”€â”€â—                                               â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚       (ë³´ì •ëœ ê²½ë¡œ)                                             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Loop Closure êµ¬í˜„

```python
import cv2
import numpy as np
from collections import deque

class LoopClosureDetector:
    """Bag of Words ê¸°ë°˜ ë£¨í”„ í´ë¡œì € íƒì§€"""

    def __init__(self, vocabulary_size=1000, min_score=0.3):
        self.orb = cv2.ORB_create(2000)
        self.bf = cv2.BFMatcher(cv2.NORM_HAMMING)

        self.vocabulary = None
        self.vocabulary_size = vocabulary_size
        self.min_score = min_score

        # í‚¤í”„ë ˆì„ ë°ì´í„°ë² ì´ìŠ¤
        self.keyframe_bows = []
        self.keyframe_descs = []
        self.keyframe_kps = []

        # ìµœê·¼ Nê°œ í‚¤í”„ë ˆì„ì€ ë£¨í”„ í›„ë³´ì—ì„œ ì œì™¸
        self.temporal_window = 30

    def build_vocabulary(self, training_images):
        """Vocabulary êµ¬ì¶•"""

        all_descriptors = []

        for img in training_images:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            _, desc = self.orb.detectAndCompute(gray, None)
            if desc is not None:
                all_descriptors.append(desc)

        all_desc = np.vstack(all_descriptors).astype(np.float32)

        # K-means
        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,
                   100, 0.2)
        _, _, self.vocabulary = cv2.kmeans(
            all_desc, self.vocabulary_size, None,
            criteria, 10, cv2.KMEANS_RANDOM_CENTERS
        )

        self.vocabulary = self.vocabulary.astype(np.uint8)

    def compute_bow(self, descriptors):
        """BoW ë²¡í„° ê³„ì‚°"""

        if self.vocabulary is None or descriptors is None:
            return None

        matches = self.bf.match(descriptors, self.vocabulary)

        bow = np.zeros(self.vocabulary_size)
        for m in matches:
            bow[m.trainIdx] += 1

        # L2 ì •ê·œí™”
        norm = np.linalg.norm(bow)
        if norm > 0:
            bow = bow / norm

        return bow

    def add_keyframe(self, frame):
        """í‚¤í”„ë ˆì„ ì¶”ê°€"""

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        kp, desc = self.orb.detectAndCompute(gray, None)

        if desc is None:
            return -1

        bow = self.compute_bow(desc)

        self.keyframe_bows.append(bow)
        self.keyframe_descs.append(desc)
        self.keyframe_kps.append(kp)

        return len(self.keyframe_bows) - 1

    def detect_loop(self, query_idx):
        """ë£¨í”„ í›„ë³´ íƒì§€"""

        if query_idx < self.temporal_window + 1:
            return None, 0

        query_bow = self.keyframe_bows[query_idx]

        best_match = -1
        best_score = 0

        # ì‹œê°„ì ìœ¼ë¡œ ë©€ë¦¬ ë–¨ì–´ì§„ í‚¤í”„ë ˆì„ë§Œ ê²€ìƒ‰
        for i in range(query_idx - self.temporal_window):
            score = np.dot(query_bow, self.keyframe_bows[i])

            if score > best_score and score > self.min_score:
                best_score = score
                best_match = i

        if best_match >= 0:
            return best_match, best_score

        return None, 0

    def verify_loop(self, query_idx, candidate_idx, min_inliers=50):
        """ê¸°í•˜í•™ì  ê²€ì¦ìœ¼ë¡œ ë£¨í”„ í™•ì¸"""

        desc1 = self.keyframe_descs[query_idx]
        desc2 = self.keyframe_descs[candidate_idx]
        kp1 = self.keyframe_kps[query_idx]
        kp2 = self.keyframe_kps[candidate_idx]

        # íŠ¹ì§•ì  ë§¤ì¹­
        matches = self.bf.knnMatch(desc1, desc2, k=2)

        good_matches = []
        for m, n in matches:
            if m.distance < 0.75 * n.distance:
                good_matches.append(m)

        if len(good_matches) < 8:
            return False, None

        # Fundamental Matrixë¡œ ê¸°í•˜í•™ì  ê²€ì¦
        pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches])
        pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches])

        F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC)

        if mask is None:
            return False, None

        num_inliers = np.sum(mask)

        if num_inliers >= min_inliers:
            return True, {
                'query_idx': query_idx,
                'match_idx': candidate_idx,
                'inliers': num_inliers,
                'pts1': pts1[mask.ravel() == 1],
                'pts2': pts2[mask.ravel() == 1]
            }

        return False, None


class PoseGraphOptimizer:
    """ê°„ë‹¨í•œ í¬ì¦ˆ ê·¸ë˜í”„ ìµœì í™”"""

    def __init__(self):
        self.poses = []         # ë…¸ë“œ (í¬ì¦ˆ)
        self.edges = []         # ì—£ì§€ (ìƒëŒ€ ë³€í™˜)
        self.loop_constraints = []  # ë£¨í”„ ì œì•½

    def add_pose(self, pose):
        """í¬ì¦ˆ ë…¸ë“œ ì¶”ê°€"""
        self.poses.append(pose.copy())
        return len(self.poses) - 1

    def add_odometry_edge(self, i, j, relative_pose, info_matrix=None):
        """ì˜¤ë„ë©”íŠ¸ë¦¬ ì—£ì§€ ì¶”ê°€"""

        if info_matrix is None:
            info_matrix = np.eye(3)

        self.edges.append({
            'from': i,
            'to': j,
            'measurement': relative_pose,
            'info': info_matrix
        })

    def add_loop_constraint(self, i, j, relative_pose, info_matrix=None):
        """ë£¨í”„ ì œì•½ ì¶”ê°€"""

        if info_matrix is None:
            # ë£¨í”„ ì œì•½ì€ ë†’ì€ ê°€ì¤‘ì¹˜
            info_matrix = np.eye(3) * 100

        self.loop_constraints.append({
            'from': i,
            'to': j,
            'measurement': relative_pose,
            'info': info_matrix
        })

    def optimize(self, num_iterations=10):
        """ê·¸ë˜í”„ ìµœì í™” (Gauss-Newton)"""

        # ê°„ë‹¨í•œ êµ¬í˜„ (ì‹¤ì œë¡œëŠ” g2o, Ceres ë“± ì‚¬ìš©)
        print("í¬ì¦ˆ ê·¸ë˜í”„ ìµœì í™”ëŠ” g2o ë“± ì „ë¬¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¶Œì¥")

        # ë£¨í”„ ì œì•½ì„ ì´ìš©í•œ ê°„ë‹¨í•œ ë³´ì •
        for constraint in self.loop_constraints:
            i = constraint['from']
            j = constraint['to']

            # ëˆ„ì  ë“œë¦¬í”„íŠ¸ ê³„ì‚°
            drift = self.poses[j][:2] - self.poses[i][:2]
            drift -= constraint['measurement'][:2]

            # ì„ í˜• ë³´ê°„ìœ¼ë¡œ ë“œë¦¬í”„íŠ¸ ë¶„ë°°
            for k in range(i, j + 1):
                alpha = (k - i) / (j - i) if j > i else 0
                self.poses[k][:2] -= alpha * drift

        return self.poses
```

---

## 6. SLAM êµ¬í˜„ ì‹¤ìŠµ

### ê°„ë‹¨í•œ SLAM ì‹œìŠ¤í…œ

```python
import cv2
import numpy as np

class SimpleVSLAM:
    """ê°„ë‹¨í•œ Visual SLAM ì‹œìŠ¤í…œ"""

    def __init__(self, K):
        self.K = K

        # ëª¨ë“ˆ
        self.vo = MonocularVO(K)
        self.loop_detector = LoopClosureDetector()
        self.pose_graph = PoseGraphOptimizer()

        # ìƒíƒœ
        self.frame_count = 0
        self.keyframe_interval = 10

    def process_frame(self, frame):
        """í”„ë ˆì„ ì²˜ë¦¬"""

        self.frame_count += 1

        # Visual Odometry
        R, t = self.vo.process_frame(frame)

        # í‚¤í”„ë ˆì„ ì¶”ê°€
        if self.frame_count % self.keyframe_interval == 0:
            kf_idx = self.loop_detector.add_keyframe(frame)

            # í¬ì¦ˆ ê·¸ë˜í”„ì— ë…¸ë“œ ì¶”ê°€
            pose = np.array([t[0, 0], t[1, 0], 0])  # 2D ê·¼ì‚¬
            node_idx = self.pose_graph.add_pose(pose)

            # ì´ì „ í‚¤í”„ë ˆì„ê³¼ ì—£ì§€ ì—°ê²°
            if node_idx > 0:
                prev_pose = self.pose_graph.poses[node_idx - 1]
                relative = pose - prev_pose
                self.pose_graph.add_odometry_edge(
                    node_idx - 1, node_idx, relative
                )

            # ë£¨í”„ íƒì§€
            if kf_idx > 30:  # ì¶©ë¶„í•œ í‚¤í”„ë ˆì„ í›„
                candidate, score = self.loop_detector.detect_loop(kf_idx)

                if candidate is not None:
                    verified, loop_info = self.loop_detector.verify_loop(
                        kf_idx, candidate
                    )

                    if verified:
                        print(f"Loop detected: {kf_idx} -> {candidate}")

                        # ë£¨í”„ ì œì•½ ì¶”ê°€
                        relative = pose - self.pose_graph.poses[candidate]
                        self.pose_graph.add_loop_constraint(
                            candidate, node_idx, relative
                        )

                        # ìµœì í™”
                        self.pose_graph.optimize()

        return R, t

    def get_map(self):
        """ë§µ ë°˜í™˜"""
        return self.vo.get_trajectory()

    def get_optimized_trajectory(self):
        """ìµœì í™”ëœ ê¶¤ì  ë°˜í™˜"""
        return np.array(self.pose_graph.poses)
```

### ì‹œê°í™”

```python
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

def visualize_slam_result(trajectory, loop_closures=None):
    """SLAM ê²°ê³¼ ì‹œê°í™”"""

    fig = plt.figure(figsize=(12, 5))

    # 2D ê¶¤ì 
    ax1 = fig.add_subplot(121)
    ax1.plot(trajectory[:, 0], trajectory[:, 1], 'b-', linewidth=1)
    ax1.scatter(trajectory[0, 0], trajectory[0, 1],
               c='green', s=100, marker='o', label='Start')
    ax1.scatter(trajectory[-1, 0], trajectory[-1, 1],
               c='red', s=100, marker='x', label='End')

    if loop_closures:
        for lc in loop_closures:
            i, j = lc['from'], lc['to']
            ax1.plot([trajectory[i, 0], trajectory[j, 0]],
                    [trajectory[i, 1], trajectory[j, 1]],
                    'g--', linewidth=2, alpha=0.5)

    ax1.set_xlabel('X')
    ax1.set_ylabel('Y')
    ax1.set_title('2D Trajectory')
    ax1.legend()
    ax1.axis('equal')
    ax1.grid(True)

    # 3D ê¶¤ì 
    ax2 = fig.add_subplot(122, projection='3d')
    ax2.plot(trajectory[:, 0], trajectory[:, 1], trajectory[:, 2],
            'b-', linewidth=1)

    ax2.set_xlabel('X')
    ax2.set_ylabel('Y')
    ax2.set_zlabel('Z')
    ax2.set_title('3D Trajectory')

    plt.tight_layout()
    plt.show()

def visualize_occupancy_map(occupancy_map, trajectory=None):
    """ì ìœ  ë§µ ì‹œê°í™”"""

    plt.figure(figsize=(10, 10))

    # ë§µ í‘œì‹œ
    plt.imshow(occupancy_map, cmap='gray', origin='lower')

    # ê¶¤ì  ì˜¤ë²„ë ˆì´
    if trajectory is not None:
        # ë§µ ì¢Œí‘œë¡œ ë³€í™˜
        map_center = occupancy_map.shape[0] // 2
        resolution = 0.05
        traj_map = trajectory / resolution + map_center

        plt.plot(traj_map[:, 0], traj_map[:, 1], 'r-', linewidth=2)
        plt.scatter(traj_map[0, 0], traj_map[0, 1], c='green', s=100)
        plt.scatter(traj_map[-1, 0], traj_map[-1, 1], c='blue', s=100)

    plt.title('Occupancy Grid Map')
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.colorbar(label='Occupancy Probability')
    plt.show()
```

---

## 7. ì—°ìŠµ ë¬¸ì œ

### ë¬¸ì œ 1: Visual Odometry êµ¬í˜„

ë‹¨ì•ˆ Visual Odometryë¥¼ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­**:
- ORB íŠ¹ì§• ê²€ì¶œ
- ê´‘í•™ íë¦„ ë˜ëŠ” ë””ìŠ¤í¬ë¦½í„° ë§¤ì¹­
- Essential Matrixë¡œ í¬ì¦ˆ ì¶”ì •
- ê¶¤ì  ì‹œê°í™”

<details>
<summary>íŒíŠ¸</summary>

```python
# Essential Matrix
E, mask = cv2.findEssentialMat(pts1, pts2, K)
_, R, t, _ = cv2.recoverPose(E, pts1, pts2, K)

# í¬ì¦ˆ ëˆ„ì 
cur_t = cur_t + cur_R @ t
cur_R = R @ cur_R
```

</details>

### ë¬¸ì œ 2: ë£¨í”„ í´ë¡œì € íƒì§€

BoW ê¸°ë°˜ ë£¨í”„ í´ë¡œì €ë¥¼ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­**:
- ORB vocabulary êµ¬ì¶•
- BoW ë²¡í„° ê³„ì‚°
- ìœ ì‚¬ë„ ê¸°ë°˜ í›„ë³´ íƒì§€
- ê¸°í•˜í•™ì  ê²€ì¦

<details>
<summary>íŒíŠ¸</summary>

```python
# BoW ìœ ì‚¬ë„
score = np.dot(bow1, bow2)

# ê¸°í•˜í•™ì  ê²€ì¦
F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC)
inliers = np.sum(mask)
```

</details>

### ë¬¸ì œ 3: ICP êµ¬í˜„

ICP ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­**:
- ìµœê·¼ì ‘ ëŒ€ì‘ì  ê²€ìƒ‰
- SVDë¡œ ë³€í™˜ ì¶”ì •
- ë°˜ë³µ ìµœì í™”
- ìˆ˜ë ´ ì¡°ê±´

<details>
<summary>íŒíŠ¸</summary>

```python
# SVDë¡œ R, t ê³„ì‚°
H = src_centered.T @ tgt_centered
U, _, Vt = np.linalg.svd(H)
R = Vt.T @ U.T
t = tgt_centroid - R @ src_centroid
```

</details>

### ë¬¸ì œ 4: ì ìœ  ê²©ì ë§µ

LiDAR ë°ì´í„°ë¡œ ì ìœ  ê²©ì ë§µì„ ìƒì„±í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­**:
- ìŠ¤ìº” ë°ì´í„°ë¥¼ í¬ì¸íŠ¸ë¡œ ë³€í™˜
- ê²©ì ì¢Œí‘œ ë³€í™˜
- ì ìœ  í™•ë¥  ì—…ë°ì´íŠ¸
- ë§µ ì‹œê°í™”

<details>
<summary>íŒíŠ¸</summary>

```python
# ë¡œê·¸ ì˜¤ì¦ˆ ì—…ë°ì´íŠ¸
log_odds = np.log(p / (1 - p))
log_odds[occupied] += 0.5
log_odds[free] -= 0.2
p = 1 / (1 + np.exp(-log_odds))
```

</details>

### ë¬¸ì œ 5: ì™„ì „í•œ SLAM ì‹œìŠ¤í…œ

VO, ë£¨í”„ í´ë¡œì €, ë§µí•‘ì„ í†µí•©í•œ SLAMì„ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­**:
- í‚¤í”„ë ˆì„ ê´€ë¦¬
- ë£¨í”„ íƒì§€ ë° ê²€ì¦
- í¬ì¦ˆ ê·¸ë˜í”„ ìµœì í™”
- 3D ë§µ ìƒì„±

<details>
<summary>íŒíŠ¸</summary>

```python
# í†µí•© ì‹œìŠ¤í…œ
class SLAM:
    def process(self, frame):
        # 1. íŠ¸ë˜í‚¹
        pose = self.track(frame)

        # 2. í‚¤í”„ë ˆì„ì´ë©´ ë§µ ì—…ë°ì´íŠ¸
        if self.is_keyframe():
            self.local_mapping()

            # 3. ë£¨í”„ íƒì§€
            if self.detect_loop():
                self.optimize_graph()
```

</details>

---

## ë‹¤ìŒ ë‹¨ê³„

- ì‹¤ì œ SLAM ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© (ORB-SLAM3, RTAB-Map)
- ROS ì—°ë™
- Visual-Inertial SLAM
- ë”¥ëŸ¬ë‹ ê¸°ë°˜ SLAM

---

## ì°¸ê³  ìë£Œ

- [ORB-SLAM3 GitHub](https://github.com/UZ-SLAMLab/ORB_SLAM3)
- [SLAM Tutorial - Cyrill Stachniss](https://www.youtube.com/playlist?list=PLgnQpQtFTOGQrZ4O5QzbIHgl3b1JHimN_)
- [Multiple View Geometry in Computer Vision](https://www.robots.ox.ac.uk/~vgg/hzbook/)
- [Probabilistic Robotics (Thrun et al.)](http://www.probabilistic-robotics.org/)
- [LOAM Paper](https://www.ri.cmu.edu/pub_files/2014/7/Ji_LidarMapping_RSS2014_v8.pdf)
- [Cartographer](https://google-cartographer.readthedocs.io/)
