# 17. GPT-4V, GPT-4o, Gemini & Claude 3

## ê°œìš”

GPT-4V(ision), GPT-4o, Gemini, Claude 3ëŠ” í˜„ì¬ ê°€ì¥ ê°•ë ¥í•œ ìƒìš© ë©€í‹°ëª¨ë‹¬ AIì…ë‹ˆë‹¤. ì´ ë ˆìŠ¨ì—ì„œëŠ” ì´ë“¤ì˜ ê¸°ëŠ¥, API ì‚¬ìš©ë²•, ê·¸ë¦¬ê³  ì‹¤ì „ ì‘ìš© ì‚¬ë¡€ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.

> **2024ë…„ ì—…ë°ì´íŠ¸**:
> - **GPT-4o** (2024.05): GPT-4ì˜ "omni" ë²„ì „, ë„¤ì´í‹°ë¸Œ ë©€í‹°ëª¨ë‹¬
> - **Gemini 1.5 Pro**: 2M í† í° ì»¨í…ìŠ¤íŠ¸, ë¹„ë””ì˜¤/ì˜¤ë””ì˜¤ ë„¤ì´í‹°ë¸Œ
> - **Claude 3 Family** (2024.03): Haiku, Sonnet, Opus ë¼ì¸ì—…
> - **Claude 3.5 Sonnet** (2024.06): ë¹„ì „ ê¸°ëŠ¥ ê°•í™”

---

## 1. GPT-4V (GPT-4 with Vision)

### 1.1 ê¸°ëŠ¥ ê°œìš”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GPT-4V ì£¼ìš” ê¸°ëŠ¥                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  ğŸ–¼ï¸ ì´ë¯¸ì§€ ì´í•´                                                  â”‚
â”‚  - ìƒì„¸ ì„¤ëª… ë° ë¶„ì„                                            â”‚
â”‚  - ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¹„êµ                                             â”‚
â”‚  - ì°¨íŠ¸/ê·¸ë˜í”„ í•´ì„                                             â”‚
â”‚                                                                  â”‚
â”‚  ğŸ“ í…ìŠ¤íŠ¸ ì¸ì‹ (OCR)                                            â”‚
â”‚  - ì†ê¸€ì”¨ ì¸ì‹                                                   â”‚
â”‚  - ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸                                                â”‚
â”‚  - ë¬¸ì„œ êµ¬ì¡° ì´í•´                                               â”‚
â”‚                                                                  â”‚
â”‚  ğŸ” ì„¸ë¶€ ë¶„ì„                                                    â”‚
â”‚  - ê°ì²´ ì‹ë³„ ë° ì¹´ìš´íŒ…                                          â”‚
â”‚  - ê³µê°„ ê´€ê³„ ì´í•´                                               â”‚
â”‚  - ì†ì„± ì¶”ë¡                                                      â”‚
â”‚                                                                  â”‚
â”‚  ğŸ’¡ ì¶”ë¡  ë° ì°½ì‘                                                  â”‚
â”‚  - ì´ë¯¸ì§€ ê¸°ë°˜ ì¶”ë¡                                              â”‚
â”‚  - ì½”ë“œ ìƒì„± (UI ìŠ¤í¬ë¦°ìƒ· â†’ ì½”ë“œ)                               â”‚
â”‚  - ì°½ì˜ì  ê¸€ì“°ê¸°                                                â”‚
â”‚                                                                  â”‚
â”‚  âš ï¸ ì œí•œ ì‚¬í•­                                                    â”‚
â”‚  - ì˜ë£Œ ì§„ë‹¨ ë¶ˆê°€                                               â”‚
â”‚  - ì–¼êµ´ ì¸ì‹/ì‹ ì› í™•ì¸ ë¶ˆê°€                                     â”‚
â”‚  - ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ë¯¸ì§€ì› (ì´ë¯¸ì§€ë§Œ)                              â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 API ì‚¬ìš©ë²•

```python
from openai import OpenAI
import base64
from pathlib import Path

client = OpenAI()

def encode_image(image_path: str) -> str:
    """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode()


def gpt4v_basic(image_path: str, prompt: str) -> str:
    """ê¸°ë³¸ ì´ë¯¸ì§€ ë¶„ì„"""

    response = client.chat.completions.create(
        model="gpt-4-vision-preview",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{encode_image(image_path)}"
                        }
                    }
                ]
            }
        ],
        max_tokens=1024
    )

    return response.choices[0].message.content


def gpt4v_multi_image(image_paths: list, prompt: str) -> str:
    """ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„"""

    content = [{"type": "text", "text": prompt}]

    for path in image_paths:
        content.append({
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{encode_image(path)}"}
        })

    response = client.chat.completions.create(
        model="gpt-4-vision-preview",
        messages=[{"role": "user", "content": content}],
        max_tokens=2048
    )

    return response.choices[0].message.content


def gpt4v_with_detail(image_path: str, prompt: str, detail: str = "high") -> str:
    """
    ìƒì„¸ ìˆ˜ì¤€ ì§€ì •

    detail:
    - "low": ë¹ ë¥´ê³  ì €ë ´, ì €í•´ìƒë„ ë¶„ì„
    - "high": ìƒì„¸ ë¶„ì„, ë” ë§ì€ í† í° ì‚¬ìš©
    - "auto": ìë™ ì„ íƒ
    """

    response = client.chat.completions.create(
        model="gpt-4-vision-preview",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{encode_image(image_path)}",
                            "detail": detail
                        }
                    }
                ]
            }
        ],
        max_tokens=1024
    )

    return response.choices[0].message.content


def gpt4v_url_image(image_url: str, prompt: str) -> str:
    """URL ì´ë¯¸ì§€ ë¶„ì„"""

    response = client.chat.completions.create(
        model="gpt-4-vision-preview",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": image_url}}
                ]
            }
        ],
        max_tokens=1024
    )

    return response.choices[0].message.content
```

### 1.3 ì‹¤ì „ ì‘ìš©

```python
class GPT4VApplications:
    """GPT-4V ì‹¤ì „ ì‘ìš©"""

    def __init__(self):
        self.client = OpenAI()

    def analyze_ui_screenshot(self, screenshot_path: str) -> dict:
        """UI ìŠ¤í¬ë¦°ìƒ· ë¶„ì„ ë° ì½”ë“œ ìƒì„±"""

        prompt = """Analyze this UI screenshot and:
        1. List all UI components visible
        2. Describe the layout structure
        3. Generate HTML/CSS code to recreate this UI

        Format your response as JSON with keys:
        - components: list of UI elements
        - layout: description of layout
        - html_code: HTML implementation
        - css_code: CSS styles
        """

        response = self._call_api(screenshot_path, prompt)

        # JSON íŒŒì‹±
        import json
        try:
            return json.loads(response)
        except:
            return {"raw_response": response}

    def extract_data_from_chart(self, chart_path: str) -> dict:
        """ì°¨íŠ¸ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""

        prompt = """Analyze this chart and extract:
        1. Chart type (bar, line, pie, etc.)
        2. Title and axis labels
        3. All data points with their values
        4. Key insights or trends

        Return as structured JSON.
        """

        return self._call_api(chart_path, prompt)

    def compare_images(self, image_paths: list) -> str:
        """ì´ë¯¸ì§€ ë¹„êµ ë¶„ì„"""

        prompt = """Compare these images and describe:
        1. Similarities
        2. Differences
        3. Which image is better quality and why
        4. Any notable features in each
        """

        return gpt4v_multi_image(image_paths, prompt)

    def ocr_with_structure(self, document_path: str) -> dict:
        """êµ¬ì¡°í™”ëœ OCR"""

        prompt = """Extract all text from this document and preserve:
        1. Headings and hierarchy
        2. Tables (as markdown)
        3. Lists (numbered and bulleted)
        4. Key-value pairs

        Return as structured markdown.
        """

        return self._call_api(document_path, prompt)

    def generate_alt_text(self, image_path: str) -> str:
        """ì›¹ ì ‘ê·¼ì„±ì„ ìœ„í•œ ëŒ€ì²´ í…ìŠ¤íŠ¸ ìƒì„±"""

        prompt = """Generate an appropriate alt text for this image.
        The alt text should be:
        1. Concise (under 125 characters)
        2. Descriptive of the main content
        3. Useful for screen reader users

        Just return the alt text, nothing else.
        """

        return self._call_api(image_path, prompt)

    def _call_api(self, image_path: str, prompt: str) -> str:
        response = self.client.chat.completions.create(
            model="gpt-4-vision-preview",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{encode_image(image_path)}",
                                "detail": "high"
                            }
                        }
                    ]
                }
            ],
            max_tokens=2048
        )
        return response.choices[0].message.content
```

---

## 2. GPT-4o (Omni)

### 2.1 GPT-4o ê°œìš”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GPT-4o vs GPT-4V ë¹„êµ                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  GPT-4V (ê¸°ì¡´):                                                  â”‚
â”‚  - í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ì…ë ¥                                          â”‚
â”‚  - ë³„ë„ì˜ ë¹„ì „ ì¸ì½”ë”                                            â”‚
â”‚  - ë¹„êµì  ëŠë¦° ì‘ë‹µ                                              â”‚
â”‚                                                                  â”‚
â”‚  GPT-4o (2024.05):                                               â”‚
â”‚  - í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ ë„¤ì´í‹°ë¸Œ                             â”‚
â”‚  - ë‹¨ì¼ ëª¨ë¸ì—ì„œ ëª¨ë“  ëª¨ë‹¬ë¦¬í‹° ì²˜ë¦¬                              â”‚
â”‚  - 2ë°° ë¹ ë¥¸ ì‘ë‹µ, 50% ì €ë ´í•œ ê°€ê²©                                â”‚
â”‚  - ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™” ê°€ëŠ¥                                         â”‚
â”‚                                                                  â”‚
â”‚  ì£¼ìš” ê°œì„ ì :                                                    â”‚
â”‚  âœ… ì†ë„: í‰ê·  320ms ì‘ë‹µ (GPT-4V ëŒ€ë¹„ 2ë°°)                      â”‚
â”‚  âœ… ë¹„ìš©: ì…ë ¥ $5/1M, ì¶œë ¥ $15/1M                                â”‚
â”‚  âœ… ë¹„ì „: í–¥ìƒëœ OCR, ì°¨íŠ¸ í•´ì„                                  â”‚
â”‚  âœ… ì˜¤ë””ì˜¤: ì‹¤ì‹œê°„ ìŒì„± ì…ì¶œë ¥                                   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 GPT-4o API ì‚¬ìš©ë²•

```python
from openai import OpenAI
import base64

client = OpenAI()

def gpt4o_vision(image_path: str, prompt: str) -> str:
    """GPT-4o ì´ë¯¸ì§€ ë¶„ì„"""

    with open(image_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode()

    response = client.chat.completions.create(
        model="gpt-4o",  # GPT-4o ì‚¬ìš©
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_data}",
                            "detail": "high"
                        }
                    }
                ]
            }
        ],
        max_tokens=1024
    )

    return response.choices[0].message.content


def gpt4o_audio(audio_path: str, prompt: str) -> str:
    """GPT-4o ì˜¤ë””ì˜¤ ë¶„ì„ (Realtime API)"""

    # ì˜¤ë””ì˜¤ íŒŒì¼ ì½ê¸°
    with open(audio_path, "rb") as f:
        audio_data = base64.b64encode(f.read()).decode()

    response = client.chat.completions.create(
        model="gpt-4o-audio-preview",
        modalities=["text"],
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "input_audio",
                        "input_audio": {
                            "data": audio_data,
                            "format": "wav"
                        }
                    }
                ]
            }
        ]
    )

    return response.choices[0].message.content


# GPT-4o-mini: ì €ë¹„ìš© ë²„ì „
def gpt4o_mini_vision(image_path: str, prompt: str) -> str:
    """GPT-4o-mini: ë¹ ë¥´ê³  ì €ë ´í•œ ë¹„ì „ ëª¨ë¸"""

    with open(image_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode()

    response = client.chat.completions.create(
        model="gpt-4o-mini",  # ì €ë¹„ìš© ë²„ì „
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}
                    }
                ]
            }
        ],
        max_tokens=512
    )

    return response.choices[0].message.content
```

---

## 3. Google Gemini

### 2.1 Gemini ëª¨ë¸ ë¼ì¸ì—…

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Gemini ëª¨ë¸ ë¹„êµ                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Gemini 1.5 Flash:                                              â”‚
â”‚  - ë¹ ë¥¸ ì‘ë‹µ, ì €ë¹„ìš©                                            â”‚
â”‚  - 1M í† í° ì»¨í…ìŠ¤íŠ¸                                             â”‚
â”‚  - ì‹¤ì‹œê°„ ì‘ìš©ì— ì í•©                                           â”‚
â”‚                                                                  â”‚
â”‚  Gemini 1.5 Pro:                                                â”‚
â”‚  - ìµœê³  ì„±ëŠ¥                                                    â”‚
â”‚  - 2M í† í° ì»¨í…ìŠ¤íŠ¸                                             â”‚
â”‚  - ë³µì¡í•œ ì¶”ë¡ , ì½”ë“œ ìƒì„±                                       â”‚
â”‚                                                                  â”‚
â”‚  Gemini 1.0 Ultra:                                              â”‚
â”‚  - ê°€ì¥ í° ëª¨ë¸                                                 â”‚
â”‚  - ë³µì¡í•œ ë©€í‹°ëª¨ë‹¬ íƒœìŠ¤í¬                                       â”‚
â”‚                                                                  â”‚
â”‚  íŠ¹ë³„ ê¸°ëŠ¥:                                                      â”‚
â”‚  - ë„¤ì´í‹°ë¸Œ ë©€í‹°ëª¨ë‹¬ (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤)           â”‚
â”‚  - ì´ˆì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ (1ì‹œê°„ ë¹„ë””ì˜¤ ë¶„ì„ ê°€ëŠ¥)                     â”‚
â”‚  - Code execution ë‚´ì¥                                          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Gemini API ì‚¬ìš©ë²•

```python
import google.generativeai as genai
from PIL import Image

# API í‚¤ ì„¤ì •
genai.configure(api_key="YOUR_API_KEY")

def gemini_basic(image_path: str, prompt: str) -> str:
    """ê¸°ë³¸ ì´ë¯¸ì§€ ë¶„ì„"""

    model = genai.GenerativeModel('gemini-1.5-pro')

    image = Image.open(image_path)

    response = model.generate_content([prompt, image])

    return response.text


def gemini_multi_image(image_paths: list, prompt: str) -> str:
    """ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„"""

    model = genai.GenerativeModel('gemini-1.5-pro')

    content = [prompt]
    for path in image_paths:
        content.append(Image.open(path))

    response = model.generate_content(content)

    return response.text


def gemini_video_analysis(video_path: str, prompt: str) -> str:
    """ë¹„ë””ì˜¤ ë¶„ì„ (Gemini íŠ¹í™” ê¸°ëŠ¥)"""

    model = genai.GenerativeModel('gemini-1.5-pro')

    # ë¹„ë””ì˜¤ ì—…ë¡œë“œ
    video_file = genai.upload_file(video_path)

    # ì²˜ë¦¬ ì™„ë£Œ ëŒ€ê¸°
    import time
    while video_file.state.name == "PROCESSING":
        time.sleep(10)
        video_file = genai.get_file(video_file.name)

    if video_file.state.name == "FAILED":
        raise ValueError("Video processing failed")

    response = model.generate_content([prompt, video_file])

    return response.text


def gemini_long_context(documents: list, query: str) -> str:
    """ê¸´ ë¬¸ì„œ ë¶„ì„ (1M+ í† í°)"""

    model = genai.GenerativeModel('gemini-1.5-pro')

    # ëª¨ë“  ë¬¸ì„œ ê²°í•©
    content = [query]
    for doc in documents:
        if doc.endswith('.pdf'):
            content.append(genai.upload_file(doc))
        elif doc.endswith(('.jpg', '.png')):
            content.append(Image.open(doc))
        else:
            with open(doc, 'r') as f:
                content.append(f.read())

    response = model.generate_content(content)

    return response.text


def gemini_with_code_execution(prompt: str) -> dict:
    """ì½”ë“œ ì‹¤í–‰ ê¸°ëŠ¥"""

    model = genai.GenerativeModel(
        'gemini-1.5-pro',
        tools='code_execution'
    )

    response = model.generate_content(prompt)

    # ì‹¤í–‰ëœ ì½”ë“œì™€ ê²°ê³¼ ì¶”ì¶œ
    result = {
        'text': response.text,
        'code_execution': []
    }

    for part in response.parts:
        if hasattr(part, 'code_execution_result'):
            result['code_execution'].append({
                'code': part.text,
                'output': part.code_execution_result.output
            })

    return result
```

### 2.3 Gemini íŠ¹í™” ì‘ìš©

```python
class GeminiApplications:
    """Gemini íŠ¹í™” ì‘ìš©"""

    def __init__(self):
        self.model = genai.GenerativeModel('gemini-1.5-pro')

    def analyze_long_video(
        self,
        video_path: str,
        questions: list
    ) -> dict:
        """ê¸´ ë¹„ë””ì˜¤ ë¶„ì„ (1ì‹œê°„+)"""

        video_file = self._upload_and_wait(video_path)

        results = {}

        for question in questions:
            prompt = f"""Analyze this video and answer: {question}

            Provide timestamps when relevant.
            """

            response = self.model.generate_content([prompt, video_file])
            results[question] = response.text

        return results

    def multimodal_reasoning(
        self,
        images: list,
        audio_path: str = None,
        text: str = None
    ) -> str:
        """ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ """

        content = []

        if text:
            content.append(text)

        for img_path in images:
            content.append(Image.open(img_path))

        if audio_path:
            audio_file = self._upload_and_wait(audio_path)
            content.append(audio_file)

        response = self.model.generate_content(content)

        return response.text

    def research_assistant(
        self,
        pdf_paths: list,
        research_question: str
    ) -> dict:
        """ì—°êµ¬ ë³´ì¡° (ê¸´ ë¬¸ì„œ ë¶„ì„)"""

        # PDF ì—…ë¡œë“œ
        files = [self._upload_and_wait(path) for path in pdf_paths]

        prompt = f"""You are a research assistant. Analyze these academic papers
        and answer the following research question:

        {research_question}

        Structure your response as:
        1. Summary of relevant findings from each paper
        2. Synthesis of the findings
        3. Gaps or contradictions
        4. Suggested future directions
        """

        content = [prompt] + files

        response = self.model.generate_content(content)

        return {
            'answer': response.text,
            'sources': pdf_paths
        }

    def _upload_and_wait(self, file_path: str):
        """íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬ ëŒ€ê¸°"""
        import time

        file = genai.upload_file(file_path)

        while file.state.name == "PROCESSING":
            time.sleep(5)
            file = genai.get_file(file.name)

        return file
```

---

## 4. Anthropic Claude 3

### 4.1 Claude 3 ëª¨ë¸ ë¼ì¸ì—…

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Claude 3 Family (2024.03)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Claude 3 Haiku:                                                 â”‚
â”‚  - ê°€ì¥ ë¹ ë¥´ê³  ì €ë ´                                              â”‚
â”‚  - ì‹¤ì‹œê°„ ì‘ìš©, ëŒ€ëŸ‰ ì²˜ë¦¬                                        â”‚
â”‚  - ë¹„ì „ ì§€ì›                                                     â”‚
â”‚                                                                  â”‚
â”‚  Claude 3 Sonnet:                                                â”‚
â”‚  - ì†ë„ì™€ ì„±ëŠ¥ì˜ ê· í˜•                                            â”‚
â”‚  - ëŒ€ë¶€ë¶„ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ë„ì— ì í•©                                 â”‚
â”‚  - ë¹„ì „ ì§€ì›                                                     â”‚
â”‚                                                                  â”‚
â”‚  Claude 3 Opus:                                                  â”‚
â”‚  - ìµœê³  ì„±ëŠ¥                                                     â”‚
â”‚  - ë³µì¡í•œ ì¶”ë¡ , ë¶„ì„ íƒœìŠ¤í¬                                      â”‚
â”‚  - ë¹„ì „ ì§€ì›                                                     â”‚
â”‚                                                                  â”‚
â”‚  Claude 3.5 Sonnet (2024.06):                                    â”‚
â”‚  - Opus ìˆ˜ì¤€ ì„±ëŠ¥, Sonnet ê°€ê²©                                   â”‚
â”‚  - í–¥ìƒëœ ë¹„ì „, ì½”ë”© ëŠ¥ë ¥                                        â”‚
â”‚  - 200K í† í° ì»¨í…ìŠ¤íŠ¸                                            â”‚
â”‚                                                                  â”‚
â”‚  íŠ¹ì§•:                                                            â”‚
â”‚  âœ… 200K ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° (ì „ ëª¨ë¸)                                â”‚
â”‚  âœ… ë©€í‹°ëª¨ë‹¬: ì´ë¯¸ì§€ ì´í•´                                         â”‚
â”‚  âœ… ì•ˆì „ì„±: Constitutional AI ì ìš©                                â”‚
â”‚  âœ… ë„êµ¬ ì‚¬ìš©: Function Calling ì§€ì›                              â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Claude API ì‚¬ìš©ë²•

```python
import anthropic
import base64

client = anthropic.Anthropic()


def claude_vision(image_path: str, prompt: str, model: str = "claude-sonnet-4-20250514") -> str:
    """Claude ë¹„ì „ ë¶„ì„"""

    # ì´ë¯¸ì§€ ì¸ì½”ë”©
    with open(image_path, "rb") as f:
        image_data = base64.standard_b64encode(f.read()).decode("utf-8")

    # ë¯¸ë””ì–´ íƒ€ì… ê²°ì •
    if image_path.endswith(".png"):
        media_type = "image/png"
    elif image_path.endswith(".gif"):
        media_type = "image/gif"
    elif image_path.endswith(".webp"):
        media_type = "image/webp"
    else:
        media_type = "image/jpeg"

    message = client.messages.create(
        model=model,
        max_tokens=1024,
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": media_type,
                            "data": image_data,
                        },
                    },
                    {
                        "type": "text",
                        "text": prompt
                    }
                ],
            }
        ],
    )

    return message.content[0].text


def claude_multi_image(image_paths: list, prompt: str) -> str:
    """Claude ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„"""

    content = []

    for path in image_paths:
        with open(path, "rb") as f:
            image_data = base64.standard_b64encode(f.read()).decode("utf-8")

        media_type = "image/png" if path.endswith(".png") else "image/jpeg"

        content.append({
            "type": "image",
            "source": {
                "type": "base64",
                "media_type": media_type,
                "data": image_data,
            }
        })

    content.append({"type": "text", "text": prompt})

    message = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=2048,
        messages=[{"role": "user", "content": content}],
    )

    return message.content[0].text


def claude_with_tools(prompt: str, image_path: str = None) -> dict:
    """Claude Tool Use (Function Calling)"""

    tools = [
        {
            "name": "get_weather",
            "description": "Get current weather for a location",
            "input_schema": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "City name"
                    }
                },
                "required": ["location"]
            }
        }
    ]

    content = [{"type": "text", "text": prompt}]

    if image_path:
        with open(image_path, "rb") as f:
            image_data = base64.standard_b64encode(f.read()).decode("utf-8")
        content.insert(0, {
            "type": "image",
            "source": {
                "type": "base64",
                "media_type": "image/jpeg",
                "data": image_data,
            }
        })

    message = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=1024,
        tools=tools,
        messages=[{"role": "user", "content": content}],
    )

    return {
        "content": message.content,
        "stop_reason": message.stop_reason
    }
```

### 4.3 Claude íŠ¹í™” ê¸°ëŠ¥

```python
class ClaudeApplications:
    """Claude íŠ¹í™” ì‘ìš©"""

    def __init__(self):
        self.client = anthropic.Anthropic()

    def long_document_analysis(self, document_text: str, query: str) -> str:
        """ê¸´ ë¬¸ì„œ ë¶„ì„ (200K í† í°)"""

        message = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=4096,
            messages=[
                {
                    "role": "user",
                    "content": f"""ë‹¤ìŒ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

ë¬¸ì„œ:
{document_text}

ì§ˆë¬¸: {query}
"""
                }
            ],
        )

        return message.content[0].text

    def code_review(self, code: str, language: str = "python") -> str:
        """ì½”ë“œ ë¦¬ë·°"""

        message = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=2048,
            messages=[
                {
                    "role": "user",
                    "content": f"""ë‹¤ìŒ {language} ì½”ë“œë¥¼ ë¦¬ë·°í•´ì£¼ì„¸ìš”.

```{language}
{code}
```

ë‹¤ìŒì„ í¬í•¨í•´ì£¼ì„¸ìš”:
1. ì ì¬ì  ë²„ê·¸
2. ì„±ëŠ¥ ê°œì„  ì‚¬í•­
3. ì½”ë“œ ìŠ¤íƒ€ì¼ ì œì•ˆ
4. ë³´ì•ˆ ë¬¸ì œ
"""
                }
            ],
        )

        return message.content[0].text

    def structured_output(self, image_path: str, schema: dict) -> dict:
        """êµ¬ì¡°í™”ëœ ì¶œë ¥ ìƒì„±"""
        import json

        with open(image_path, "rb") as f:
            image_data = base64.standard_b64encode(f.read()).decode("utf-8")

        message = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=2048,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/jpeg",
                                "data": image_data,
                            }
                        },
                        {
                            "type": "text",
                            "text": f"""ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆì— ë§ì¶° ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì„¸ìš”:

{json.dumps(schema, indent=2, ensure_ascii=False)}

JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”."""
                        }
                    ]
                }
            ],
        )

        return json.loads(message.content[0].text)
```

---

## 5. ë¹„êµ ë° ì„ íƒ ê°€ì´ë“œ

### 5.1 ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ë¹„êµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    2024 ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ë¹„êµ                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ê¸°ëŠ¥            GPT-4o      Gemini 1.5 Pro   Claude 3.5 Sonnet            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  ì´ë¯¸ì§€ ì´í•´     â˜…â˜…â˜…â˜…â˜…     â˜…â˜…â˜…â˜…â˜…         â˜…â˜…â˜…â˜…â˜…                    â”‚
â”‚  ë¹„ë””ì˜¤ ë¶„ì„     âœ—           â˜…â˜…â˜…â˜…â˜… (ë„¤ì´í‹°ë¸Œ) âœ—                          â”‚
â”‚  ì˜¤ë””ì˜¤ ë¶„ì„     â˜…â˜…â˜…â˜…â˜†     â˜…â˜…â˜…â˜…â˜†         âœ—                          â”‚
â”‚  ì»¨í…ìŠ¤íŠ¸        128K        2M               200K                         â”‚
â”‚  ì½”ë“œ ì‹¤í–‰       âœ—           â˜…â˜…â˜…â˜…â˜† (ë‚´ì¥)  âœ—                          â”‚
â”‚  ì†ë„            â˜…â˜…â˜…â˜…â˜…     â˜…â˜…â˜…â˜…â˜† (Flash) â˜…â˜…â˜…â˜…â˜†                    â”‚
â”‚  ê°€ê²©            ì¤‘ê°„        ë‚®ìŒ             ì¤‘ê°„                         â”‚
â”‚  ì½”ë”© ëŠ¥ë ¥       â˜…â˜…â˜…â˜…â˜†     â˜…â˜…â˜…â˜…â˜†         â˜…â˜…â˜…â˜…â˜…                    â”‚
â”‚  ì¶”ë¡  ëŠ¥ë ¥       â˜…â˜…â˜…â˜…â˜…     â˜…â˜…â˜…â˜…â˜†         â˜…â˜…â˜…â˜…â˜…                    â”‚
â”‚                                                                             â”‚
â”‚  ì¶”ì²œ ì‚¬ìš© ì‚¬ë¡€:                                                            â”‚
â”‚  - GPT-4o: ì‹¤ì‹œê°„ ë©€í‹°ëª¨ë‹¬, ìŒì„± ëŒ€í™”, ë¹ ë¥¸ ì‘ë‹µ í•„ìš” ì‹œ                    â”‚
â”‚  - Gemini: ë¹„ë””ì˜¤ ë¶„ì„, ì´ˆì¥ë¬¸ ë¬¸ì„œ, ë©€í‹°ëª¨ë‹¬ ë³µí•© íƒœìŠ¤í¬                   â”‚
â”‚  - Claude: ë³µì¡í•œ ì¶”ë¡ , ì½”ë“œ ë¦¬ë·°, ê¸´ ë¬¸ì„œ ë¶„ì„, ì•ˆì „ì„± ì¤‘ìš” ì‹œ             â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 ì‚¬ìš© ì‚¬ë¡€ë³„ ì„ íƒ

```python
def select_model(use_case: str) -> str:
    """ì‚¬ìš© ì‚¬ë¡€ë³„ ëª¨ë¸ ì„ íƒ (2024 ì—…ë°ì´íŠ¸)"""

    recommendations = {
        # GPT-4oê°€ ì¢‹ì€ ê²½ìš°
        "ui_to_code": "gpt-4o",
        "realtime_chat": "gpt-4o",
        "voice_assistant": "gpt-4o-audio-preview",
        "quick_vision": "gpt-4o",

        # Geminiê°€ ì¢‹ì€ ê²½ìš°
        "video_analysis": "gemini-1.5-pro",
        "very_long_document": "gemini-1.5-pro",  # 2M ì»¨í…ìŠ¤íŠ¸
        "audio_transcription": "gemini-1.5-pro",
        "multimodal_app": "gemini-1.5-pro",

        # Claudeê°€ ì¢‹ì€ ê²½ìš°
        "complex_reasoning": "claude-sonnet-4-20250514",
        "code_review": "claude-sonnet-4-20250514",
        "long_document": "claude-sonnet-4-20250514",  # 200K ì»¨í…ìŠ¤íŠ¸
        "safety_critical": "claude-sonnet-4-20250514",

        # ë¹„ìš© ìµœì í™”
        "high_volume": "gemini-1.5-flash",
        "quick_caption": "gpt-4o-mini",
        "simple_classification": "claude-3-haiku-20240307",
    }

    return recommendations.get(use_case, "gpt-4o")
```

---

## 6. ë¹„ìš© ìµœì í™”

### 6.1 ë¹„ìš© ê³„ì‚°

```python
class CostEstimator:
    """API ë¹„ìš© ì¶”ì •"""

    # 2024ë…„ ê¸°ì¤€ ê°€ê²© (USD per 1M tokens)
    PRICING = {
        "gpt-4-vision-preview": {
            "input": 10.0,   # per 1M tokens
            "output": 30.0,  # per 1M tokens
            "image_low": 85,   # tokens
            "image_high": 765, # tokens (base) + tiles
        },
        "gpt-4o": {
            "input": 5.0,    # per 1M tokens
            "output": 15.0,  # per 1M tokens
            "image_low": 85,
            "image_high": 765,
        },
        "gpt-4o-mini": {
            "input": 0.15,   # per 1M tokens
            "output": 0.60,  # per 1M tokens
            "image_low": 85,
            "image_high": 765,
        },
        "gemini-1.5-pro": {
            "input": 1.25,   # per 1M tokens
            "output": 5.0,
            "image": 258,  # tokens per image
            "video": 263,  # tokens per second
            "audio": 32,   # tokens per second
        },
        "gemini-1.5-flash": {
            "input": 0.075,
            "output": 0.30,
        },
        "claude-3-opus": {
            "input": 15.0,   # per 1M tokens
            "output": 75.0,
        },
        "claude-sonnet-4-20250514": {
            "input": 3.0,    # per 1M tokens
            "output": 15.0,
        },
        "claude-3-haiku": {
            "input": 0.25,   # per 1M tokens
            "output": 1.25,
        },
    }

    def estimate_gpt4v_cost(
        self,
        num_images: int,
        avg_prompt_tokens: int,
        avg_response_tokens: int,
        detail: str = "high"
    ) -> float:
        """GPT-4V ë¹„ìš© ì¶”ì •"""

        pricing = self.PRICING["gpt-4-vision-preview"]

        # ì´ë¯¸ì§€ í† í°
        if detail == "low":
            image_tokens = num_images * pricing["image_low"]
        else:
            image_tokens = num_images * pricing["image_high"]

        total_input = avg_prompt_tokens + image_tokens
        total_output = avg_response_tokens

        cost = (total_input / 1000 * pricing["input"] +
                total_output / 1000 * pricing["output"])

        return cost

    def estimate_gemini_cost(
        self,
        num_images: int = 0,
        video_seconds: int = 0,
        audio_seconds: int = 0,
        text_chars: int = 0,
        output_chars: int = 0,
        model: str = "gemini-1.5-pro"
    ) -> float:
        """Gemini ë¹„ìš© ì¶”ì •"""

        pricing = self.PRICING[model]

        input_cost = text_chars / 1000 * pricing["input"]
        output_cost = output_chars / 1000 * pricing["output"]

        if model == "gemini-1.5-pro":
            # ë©€í‹°ë¯¸ë””ì–´ ë¹„ìš©
            image_tokens = num_images * pricing["image"]
            video_tokens = video_seconds * pricing["video"]
            audio_tokens = audio_seconds * pricing["audio"]

            media_chars = (image_tokens + video_tokens + audio_tokens) * 4  # í† í° â†’ ë¬¸ì ê·¼ì‚¬
            input_cost += media_chars / 1000 * pricing["input"]

        return input_cost + output_cost


# ì‚¬ìš© ì˜ˆì‹œ
estimator = CostEstimator()

# 100ê°œ ì´ë¯¸ì§€ ë¶„ì„ ë¹„ìš© ë¹„êµ
gpt4v_cost = estimator.estimate_gpt4v_cost(
    num_images=100,
    avg_prompt_tokens=100,
    avg_response_tokens=500,
    detail="high"
)

gemini_cost = estimator.estimate_gemini_cost(
    num_images=100,
    text_chars=500,
    output_chars=2000,
    model="gemini-1.5-pro"
)

print(f"GPT-4V cost: ${gpt4v_cost:.2f}")
print(f"Gemini Pro cost: ${gemini_cost:.2f}")
```

---

## ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [OpenAI GPT-4o Documentation](https://platform.openai.com/docs/guides/vision)
- [Google Gemini API](https://ai.google.dev/docs)
- [Anthropic Claude Documentation](https://docs.anthropic.com/)

### ë²¤ì¹˜ë§ˆí¬
- [MMMU Benchmark](https://mmmu-benchmark.github.io/)
- [VQA Challenge](https://visualqa.org/)
- [LMSYS Chatbot Arena](https://chat.lmsys.org/)

### ê´€ë ¨ ë ˆìŠ¨
- [16_Vision_Language_Advanced.md](16_Vision_Language_Advanced.md)
- [24_API_Evaluation.md](24_API_Evaluation.md)
