# 17. GPT-4V & Gemini

## ê°œìš”

GPT-4V(ision)ì™€ GeminiëŠ” í˜„ì¬ ê°€ì¥ ê°•ë ¥í•œ ìƒìš© ë©€í‹°ëª¨ë‹¬ AIì…ë‹ˆë‹¤. ì´ ë ˆìŠ¨ì—ì„œëŠ” ì´ë“¤ì˜ ê¸°ëŠ¥, API ì‚¬ìš©ë²•, ê·¸ë¦¬ê³  ì‹¤ì „ ì‘ìš© ì‚¬ë¡€ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.

---

## 1. GPT-4V (GPT-4 with Vision)

### 1.1 ê¸°ëŠ¥ ê°œìš”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GPT-4V ì£¼ìš” ê¸°ëŠ¥                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  ğŸ–¼ï¸ ì´ë¯¸ì§€ ì´í•´                                                  â”‚
â”‚  - ìƒì„¸ ì„¤ëª… ë° ë¶„ì„                                            â”‚
â”‚  - ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¹„êµ                                             â”‚
â”‚  - ì°¨íŠ¸/ê·¸ë˜í”„ í•´ì„                                             â”‚
â”‚                                                                  â”‚
â”‚  ğŸ“ í…ìŠ¤íŠ¸ ì¸ì‹ (OCR)                                            â”‚
â”‚  - ì†ê¸€ì”¨ ì¸ì‹                                                   â”‚
â”‚  - ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸                                                â”‚
â”‚  - ë¬¸ì„œ êµ¬ì¡° ì´í•´                                               â”‚
â”‚                                                                  â”‚
â”‚  ğŸ” ì„¸ë¶€ ë¶„ì„                                                    â”‚
â”‚  - ê°ì²´ ì‹ë³„ ë° ì¹´ìš´íŒ…                                          â”‚
â”‚  - ê³µê°„ ê´€ê³„ ì´í•´                                               â”‚
â”‚  - ì†ì„± ì¶”ë¡                                                      â”‚
â”‚                                                                  â”‚
â”‚  ğŸ’¡ ì¶”ë¡  ë° ì°½ì‘                                                  â”‚
â”‚  - ì´ë¯¸ì§€ ê¸°ë°˜ ì¶”ë¡                                              â”‚
â”‚  - ì½”ë“œ ìƒì„± (UI ìŠ¤í¬ë¦°ìƒ· â†’ ì½”ë“œ)                               â”‚
â”‚  - ì°½ì˜ì  ê¸€ì“°ê¸°                                                â”‚
â”‚                                                                  â”‚
â”‚  âš ï¸ ì œí•œ ì‚¬í•­                                                    â”‚
â”‚  - ì˜ë£Œ ì§„ë‹¨ ë¶ˆê°€                                               â”‚
â”‚  - ì–¼êµ´ ì¸ì‹/ì‹ ì› í™•ì¸ ë¶ˆê°€                                     â”‚
â”‚  - ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ë¯¸ì§€ì› (ì´ë¯¸ì§€ë§Œ)                              â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 API ì‚¬ìš©ë²•

```python
from openai import OpenAI
import base64
from pathlib import Path

client = OpenAI()

def encode_image(image_path: str) -> str:
    """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode()


def gpt4v_basic(image_path: str, prompt: str) -> str:
    """ê¸°ë³¸ ì´ë¯¸ì§€ ë¶„ì„"""

    response = client.chat.completions.create(
        model="gpt-4-vision-preview",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{encode_image(image_path)}"
                        }
                    }
                ]
            }
        ],
        max_tokens=1024
    )

    return response.choices[0].message.content


def gpt4v_multi_image(image_paths: list, prompt: str) -> str:
    """ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„"""

    content = [{"type": "text", "text": prompt}]

    for path in image_paths:
        content.append({
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{encode_image(path)}"}
        })

    response = client.chat.completions.create(
        model="gpt-4-vision-preview",
        messages=[{"role": "user", "content": content}],
        max_tokens=2048
    )

    return response.choices[0].message.content


def gpt4v_with_detail(image_path: str, prompt: str, detail: str = "high") -> str:
    """
    ìƒì„¸ ìˆ˜ì¤€ ì§€ì •

    detail:
    - "low": ë¹ ë¥´ê³  ì €ë ´, ì €í•´ìƒë„ ë¶„ì„
    - "high": ìƒì„¸ ë¶„ì„, ë” ë§ì€ í† í° ì‚¬ìš©
    - "auto": ìë™ ì„ íƒ
    """

    response = client.chat.completions.create(
        model="gpt-4-vision-preview",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{encode_image(image_path)}",
                            "detail": detail
                        }
                    }
                ]
            }
        ],
        max_tokens=1024
    )

    return response.choices[0].message.content


def gpt4v_url_image(image_url: str, prompt: str) -> str:
    """URL ì´ë¯¸ì§€ ë¶„ì„"""

    response = client.chat.completions.create(
        model="gpt-4-vision-preview",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": image_url}}
                ]
            }
        ],
        max_tokens=1024
    )

    return response.choices[0].message.content
```

### 1.3 ì‹¤ì „ ì‘ìš©

```python
class GPT4VApplications:
    """GPT-4V ì‹¤ì „ ì‘ìš©"""

    def __init__(self):
        self.client = OpenAI()

    def analyze_ui_screenshot(self, screenshot_path: str) -> dict:
        """UI ìŠ¤í¬ë¦°ìƒ· ë¶„ì„ ë° ì½”ë“œ ìƒì„±"""

        prompt = """Analyze this UI screenshot and:
        1. List all UI components visible
        2. Describe the layout structure
        3. Generate HTML/CSS code to recreate this UI

        Format your response as JSON with keys:
        - components: list of UI elements
        - layout: description of layout
        - html_code: HTML implementation
        - css_code: CSS styles
        """

        response = self._call_api(screenshot_path, prompt)

        # JSON íŒŒì‹±
        import json
        try:
            return json.loads(response)
        except:
            return {"raw_response": response}

    def extract_data_from_chart(self, chart_path: str) -> dict:
        """ì°¨íŠ¸ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""

        prompt = """Analyze this chart and extract:
        1. Chart type (bar, line, pie, etc.)
        2. Title and axis labels
        3. All data points with their values
        4. Key insights or trends

        Return as structured JSON.
        """

        return self._call_api(chart_path, prompt)

    def compare_images(self, image_paths: list) -> str:
        """ì´ë¯¸ì§€ ë¹„êµ ë¶„ì„"""

        prompt = """Compare these images and describe:
        1. Similarities
        2. Differences
        3. Which image is better quality and why
        4. Any notable features in each
        """

        return gpt4v_multi_image(image_paths, prompt)

    def ocr_with_structure(self, document_path: str) -> dict:
        """êµ¬ì¡°í™”ëœ OCR"""

        prompt = """Extract all text from this document and preserve:
        1. Headings and hierarchy
        2. Tables (as markdown)
        3. Lists (numbered and bulleted)
        4. Key-value pairs

        Return as structured markdown.
        """

        return self._call_api(document_path, prompt)

    def generate_alt_text(self, image_path: str) -> str:
        """ì›¹ ì ‘ê·¼ì„±ì„ ìœ„í•œ ëŒ€ì²´ í…ìŠ¤íŠ¸ ìƒì„±"""

        prompt = """Generate an appropriate alt text for this image.
        The alt text should be:
        1. Concise (under 125 characters)
        2. Descriptive of the main content
        3. Useful for screen reader users

        Just return the alt text, nothing else.
        """

        return self._call_api(image_path, prompt)

    def _call_api(self, image_path: str, prompt: str) -> str:
        response = self.client.chat.completions.create(
            model="gpt-4-vision-preview",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{encode_image(image_path)}",
                                "detail": "high"
                            }
                        }
                    ]
                }
            ],
            max_tokens=2048
        )
        return response.choices[0].message.content
```

---

## 2. Google Gemini

### 2.1 Gemini ëª¨ë¸ ë¼ì¸ì—…

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Gemini ëª¨ë¸ ë¹„êµ                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Gemini 1.5 Flash:                                              â”‚
â”‚  - ë¹ ë¥¸ ì‘ë‹µ, ì €ë¹„ìš©                                            â”‚
â”‚  - 1M í† í° ì»¨í…ìŠ¤íŠ¸                                             â”‚
â”‚  - ì‹¤ì‹œê°„ ì‘ìš©ì— ì í•©                                           â”‚
â”‚                                                                  â”‚
â”‚  Gemini 1.5 Pro:                                                â”‚
â”‚  - ìµœê³  ì„±ëŠ¥                                                    â”‚
â”‚  - 2M í† í° ì»¨í…ìŠ¤íŠ¸                                             â”‚
â”‚  - ë³µì¡í•œ ì¶”ë¡ , ì½”ë“œ ìƒì„±                                       â”‚
â”‚                                                                  â”‚
â”‚  Gemini 1.0 Ultra:                                              â”‚
â”‚  - ê°€ì¥ í° ëª¨ë¸                                                 â”‚
â”‚  - ë³µì¡í•œ ë©€í‹°ëª¨ë‹¬ íƒœìŠ¤í¬                                       â”‚
â”‚                                                                  â”‚
â”‚  íŠ¹ë³„ ê¸°ëŠ¥:                                                      â”‚
â”‚  - ë„¤ì´í‹°ë¸Œ ë©€í‹°ëª¨ë‹¬ (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤)           â”‚
â”‚  - ì´ˆì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ (1ì‹œê°„ ë¹„ë””ì˜¤ ë¶„ì„ ê°€ëŠ¥)                     â”‚
â”‚  - Code execution ë‚´ì¥                                          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Gemini API ì‚¬ìš©ë²•

```python
import google.generativeai as genai
from PIL import Image

# API í‚¤ ì„¤ì •
genai.configure(api_key="YOUR_API_KEY")

def gemini_basic(image_path: str, prompt: str) -> str:
    """ê¸°ë³¸ ì´ë¯¸ì§€ ë¶„ì„"""

    model = genai.GenerativeModel('gemini-1.5-pro')

    image = Image.open(image_path)

    response = model.generate_content([prompt, image])

    return response.text


def gemini_multi_image(image_paths: list, prompt: str) -> str:
    """ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„"""

    model = genai.GenerativeModel('gemini-1.5-pro')

    content = [prompt]
    for path in image_paths:
        content.append(Image.open(path))

    response = model.generate_content(content)

    return response.text


def gemini_video_analysis(video_path: str, prompt: str) -> str:
    """ë¹„ë””ì˜¤ ë¶„ì„ (Gemini íŠ¹í™” ê¸°ëŠ¥)"""

    model = genai.GenerativeModel('gemini-1.5-pro')

    # ë¹„ë””ì˜¤ ì—…ë¡œë“œ
    video_file = genai.upload_file(video_path)

    # ì²˜ë¦¬ ì™„ë£Œ ëŒ€ê¸°
    import time
    while video_file.state.name == "PROCESSING":
        time.sleep(10)
        video_file = genai.get_file(video_file.name)

    if video_file.state.name == "FAILED":
        raise ValueError("Video processing failed")

    response = model.generate_content([prompt, video_file])

    return response.text


def gemini_long_context(documents: list, query: str) -> str:
    """ê¸´ ë¬¸ì„œ ë¶„ì„ (1M+ í† í°)"""

    model = genai.GenerativeModel('gemini-1.5-pro')

    # ëª¨ë“  ë¬¸ì„œ ê²°í•©
    content = [query]
    for doc in documents:
        if doc.endswith('.pdf'):
            content.append(genai.upload_file(doc))
        elif doc.endswith(('.jpg', '.png')):
            content.append(Image.open(doc))
        else:
            with open(doc, 'r') as f:
                content.append(f.read())

    response = model.generate_content(content)

    return response.text


def gemini_with_code_execution(prompt: str) -> dict:
    """ì½”ë“œ ì‹¤í–‰ ê¸°ëŠ¥"""

    model = genai.GenerativeModel(
        'gemini-1.5-pro',
        tools='code_execution'
    )

    response = model.generate_content(prompt)

    # ì‹¤í–‰ëœ ì½”ë“œì™€ ê²°ê³¼ ì¶”ì¶œ
    result = {
        'text': response.text,
        'code_execution': []
    }

    for part in response.parts:
        if hasattr(part, 'code_execution_result'):
            result['code_execution'].append({
                'code': part.text,
                'output': part.code_execution_result.output
            })

    return result
```

### 2.3 Gemini íŠ¹í™” ì‘ìš©

```python
class GeminiApplications:
    """Gemini íŠ¹í™” ì‘ìš©"""

    def __init__(self):
        self.model = genai.GenerativeModel('gemini-1.5-pro')

    def analyze_long_video(
        self,
        video_path: str,
        questions: list
    ) -> dict:
        """ê¸´ ë¹„ë””ì˜¤ ë¶„ì„ (1ì‹œê°„+)"""

        video_file = self._upload_and_wait(video_path)

        results = {}

        for question in questions:
            prompt = f"""Analyze this video and answer: {question}

            Provide timestamps when relevant.
            """

            response = self.model.generate_content([prompt, video_file])
            results[question] = response.text

        return results

    def multimodal_reasoning(
        self,
        images: list,
        audio_path: str = None,
        text: str = None
    ) -> str:
        """ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ """

        content = []

        if text:
            content.append(text)

        for img_path in images:
            content.append(Image.open(img_path))

        if audio_path:
            audio_file = self._upload_and_wait(audio_path)
            content.append(audio_file)

        response = self.model.generate_content(content)

        return response.text

    def research_assistant(
        self,
        pdf_paths: list,
        research_question: str
    ) -> dict:
        """ì—°êµ¬ ë³´ì¡° (ê¸´ ë¬¸ì„œ ë¶„ì„)"""

        # PDF ì—…ë¡œë“œ
        files = [self._upload_and_wait(path) for path in pdf_paths]

        prompt = f"""You are a research assistant. Analyze these academic papers
        and answer the following research question:

        {research_question}

        Structure your response as:
        1. Summary of relevant findings from each paper
        2. Synthesis of the findings
        3. Gaps or contradictions
        4. Suggested future directions
        """

        content = [prompt] + files

        response = self.model.generate_content(content)

        return {
            'answer': response.text,
            'sources': pdf_paths
        }

    def _upload_and_wait(self, file_path: str):
        """íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬ ëŒ€ê¸°"""
        import time

        file = genai.upload_file(file_path)

        while file.state.name == "PROCESSING":
            time.sleep(5)
            file = genai.get_file(file.name)

        return file
```

---

## 3. ë¹„êµ ë° ì„ íƒ ê°€ì´ë“œ

### 3.1 GPT-4V vs Gemini ë¹„êµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              GPT-4V vs Gemini ë¹„êµ                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  ê¸°ëŠ¥              GPT-4V              Gemini 1.5 Pro          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  ì´ë¯¸ì§€ ì´í•´       â˜…â˜…â˜…â˜…â˜…            â˜…â˜…â˜…â˜…â˜…                â”‚
â”‚  ë¹„ë””ì˜¤ ë¶„ì„       âœ— (í”„ë ˆì„ë§Œ)       â˜…â˜…â˜…â˜…â˜… (ë„¤ì´í‹°ë¸Œ)      â”‚
â”‚  ì˜¤ë””ì˜¤ ë¶„ì„       âœ—                  â˜…â˜…â˜…â˜…â˜†                â”‚
â”‚  ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´     128K               2M                       â”‚
â”‚  ì½”ë“œ ì‹¤í–‰         âœ—                  â˜…â˜…â˜…â˜…â˜† (ë‚´ì¥)         â”‚
â”‚  ê°€ê²©              ë†’ìŒ               ì¤‘ê°„                     â”‚
â”‚  ì†ë„              ì¤‘ê°„               FlashëŠ” ë¹ ë¦„             â”‚
â”‚  ì¼ê´€ì„±            ë†’ìŒ               ë†’ìŒ                     â”‚
â”‚                                                                â”‚
â”‚  ì¶”ì²œ ì‚¬ìš© ì‚¬ë¡€:                                               â”‚
â”‚  - GPT-4V: ë³µì¡í•œ ì´ë¯¸ì§€ ì¶”ë¡ , UI ì½”ë“œ ìƒì„±, ì •ë°€ OCR         â”‚
â”‚  - Gemini: ë¹„ë””ì˜¤ ë¶„ì„, ì´ˆì¥ë¬¸ ë¬¸ì„œ, ë©€í‹°ëª¨ë‹¬ ë³µí•© íƒœìŠ¤í¬     â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 ì‚¬ìš© ì‚¬ë¡€ë³„ ì„ íƒ

```python
def select_model(use_case: str) -> str:
    """ì‚¬ìš© ì‚¬ë¡€ë³„ ëª¨ë¸ ì„ íƒ"""

    recommendations = {
        # GPT-4Vê°€ ì¢‹ì€ ê²½ìš°
        "ui_to_code": "gpt-4-vision-preview",
        "precise_ocr": "gpt-4-vision-preview",
        "image_reasoning": "gpt-4-vision-preview",
        "chart_analysis": "gpt-4-vision-preview",

        # Geminiê°€ ì¢‹ì€ ê²½ìš°
        "video_analysis": "gemini-1.5-pro",
        "long_document": "gemini-1.5-pro",
        "audio_transcription": "gemini-1.5-pro",
        "multimodal_app": "gemini-1.5-pro",

        # ë¹„ìš© ìµœì í™”
        "high_volume": "gemini-1.5-flash",
        "quick_caption": "gemini-1.5-flash",
    }

    return recommendations.get(use_case, "gpt-4-vision-preview")
```

---

## 4. ë¹„ìš© ìµœì í™”

### 4.1 ë¹„ìš© ê³„ì‚°

```python
class CostEstimator:
    """API ë¹„ìš© ì¶”ì •"""

    # 2024ë…„ ê¸°ì¤€ ê°€ê²© (USD)
    PRICING = {
        "gpt-4-vision-preview": {
            "input": 0.01,   # per 1K tokens
            "output": 0.03,  # per 1K tokens
            "image_low": 85,   # tokens
            "image_high": 765, # tokens (base) + tiles
        },
        "gemini-1.5-pro": {
            "input": 0.00125,  # per 1K chars
            "output": 0.00375,
            "image": 258,  # tokens per image
            "video": 263,  # tokens per second
            "audio": 32,   # tokens per second
        },
        "gemini-1.5-flash": {
            "input": 0.000125,
            "output": 0.000375,
        }
    }

    def estimate_gpt4v_cost(
        self,
        num_images: int,
        avg_prompt_tokens: int,
        avg_response_tokens: int,
        detail: str = "high"
    ) -> float:
        """GPT-4V ë¹„ìš© ì¶”ì •"""

        pricing = self.PRICING["gpt-4-vision-preview"]

        # ì´ë¯¸ì§€ í† í°
        if detail == "low":
            image_tokens = num_images * pricing["image_low"]
        else:
            image_tokens = num_images * pricing["image_high"]

        total_input = avg_prompt_tokens + image_tokens
        total_output = avg_response_tokens

        cost = (total_input / 1000 * pricing["input"] +
                total_output / 1000 * pricing["output"])

        return cost

    def estimate_gemini_cost(
        self,
        num_images: int = 0,
        video_seconds: int = 0,
        audio_seconds: int = 0,
        text_chars: int = 0,
        output_chars: int = 0,
        model: str = "gemini-1.5-pro"
    ) -> float:
        """Gemini ë¹„ìš© ì¶”ì •"""

        pricing = self.PRICING[model]

        input_cost = text_chars / 1000 * pricing["input"]
        output_cost = output_chars / 1000 * pricing["output"]

        if model == "gemini-1.5-pro":
            # ë©€í‹°ë¯¸ë””ì–´ ë¹„ìš©
            image_tokens = num_images * pricing["image"]
            video_tokens = video_seconds * pricing["video"]
            audio_tokens = audio_seconds * pricing["audio"]

            media_chars = (image_tokens + video_tokens + audio_tokens) * 4  # í† í° â†’ ë¬¸ì ê·¼ì‚¬
            input_cost += media_chars / 1000 * pricing["input"]

        return input_cost + output_cost


# ì‚¬ìš© ì˜ˆì‹œ
estimator = CostEstimator()

# 100ê°œ ì´ë¯¸ì§€ ë¶„ì„ ë¹„ìš© ë¹„êµ
gpt4v_cost = estimator.estimate_gpt4v_cost(
    num_images=100,
    avg_prompt_tokens=100,
    avg_response_tokens=500,
    detail="high"
)

gemini_cost = estimator.estimate_gemini_cost(
    num_images=100,
    text_chars=500,
    output_chars=2000,
    model="gemini-1.5-pro"
)

print(f"GPT-4V cost: ${gpt4v_cost:.2f}")
print(f"Gemini Pro cost: ${gemini_cost:.2f}")
```

---

## ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [OpenAI GPT-4V Documentation](https://platform.openai.com/docs/guides/vision)
- [Google Gemini API](https://ai.google.dev/docs)

### ë²¤ì¹˜ë§ˆí¬
- [MMMU Benchmark](https://mmmu-benchmark.github.io/)
- [VQA Challenge](https://visualqa.org/)

### ê´€ë ¨ ë ˆìŠ¨
- [16_Vision_Language_Advanced.md](16_Vision_Language_Advanced.md)
- [24_API_Evaluation.md](24_API_Evaluation.md)
